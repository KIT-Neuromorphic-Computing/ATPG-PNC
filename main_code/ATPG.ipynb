{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FaultAnalysisDropout.pNN_FA as pNN\n",
    "from configuration import *\n",
    "from utils import *\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "if not os.path.exists('../experiments/FaultAnalysis/evaluation/'):\n",
    "    os.makedirs('../experiments/FaultAnalysis/evaluation/')\n",
    "\n",
    "args = parser.parse_args([])\n",
    "args = FormulateArgs(args)\n",
    "\n",
    "args.DATASET = 0\n",
    "args.SEED = 6\n",
    "args.e_train = 0.0\n",
    "args.N_fault = 1\n",
    "args.e_fault = 0.0\n",
    "\n",
    "args.dropout = 0.0\n",
    "args.fault_ratio = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Dataset Prepration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader, datainfo = GetDataLoader(args, 'valid', path='../dataset/')\n",
    "test_loader, datainfo = GetDataLoader(args, 'test',  path='../dataset/')\n",
    "pprint.pprint(datainfo)\n",
    "\n",
    "for x, y in valid_loader:\n",
    "    X_valid, y_valid = x.to(args.DEVICE), y.to(args.DEVICE)\n",
    "for x, y in test_loader:\n",
    "    X_test, y_test = x.to(args.DEVICE), y.to(args.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Model\n",
    "topology = [datainfo['N_feature']] + args.hidden + [datainfo['N_class']]\n",
    "\n",
    "tmp_pnn = pNN.pNN(topology, args).to(args.DEVICE)\n",
    "\n",
    "best_acc = 0.0\n",
    "pnn = pNN.pNN(topology, args).to(args.DEVICE)\n",
    "for seed in range(10):\n",
    "        \n",
    "        args.SEED = seed\n",
    "\n",
    "        modelname = f\"data_{args.DATASET:02d}_{datainfo['dataname']}_seed_{\n",
    "                args.SEED:02d}_epsilon_{args.e_train}_dropout_{args.dropout}_fault_ratio_{args.fault_ratio}.model\"\n",
    "        trained_model = torch.load(f'../trained_models/tanh_0_FaultAnalysisNormal/models/{modelname}')\n",
    "\n",
    "        for i, j in zip(trained_model.model, tmp_pnn.model):\n",
    "                j.theta_.data = i.theta_.data.clone()\n",
    "                \n",
    "        tmp_pnn.UpdateFault(N_fault=args.N_fault, e_fault=args.e_fault)\n",
    "        tmp_pnn.UpdateArgs(args)\n",
    "        \n",
    "        pred_valid = tmp_pnn(X_valid)[0,0,:,:]\n",
    "        base_acc_valid = (torch.argmax(pred_valid, dim=1) ==\n",
    "                                y_valid).sum() / y_valid.numel()\n",
    "        print(f\"Seed: {seed}, Accuracy: {base_acc_valid}\")\n",
    "        if best_acc < base_acc_valid:\n",
    "            best_acc = base_acc_valid\n",
    "            best_seed = seed\n",
    "            pnn = pNN.pNN(topology, args).to(args.DEVICE)\n",
    "            for i, j in zip(trained_model.model, pnn.model):\n",
    "                j.theta_.data = i.theta_.data.clone()\n",
    "                pnn.UpdateFault(N_fault=args.N_fault, e_fault=args.e_fault)\n",
    "                pnn.UpdateArgs(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_valid = pnn(X_valid)[0,0,:,:]\n",
    "base_acc_valid = (torch.argmax(pred_valid, dim=1) ==\n",
    "                                y_valid).sum() / y_valid.numel()\n",
    "base_acc_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_valid = pnn(X_valid)[0,0,:,:]\n",
    "base_acc_valid = (torch.argmax(pred_valid, dim=1) ==\n",
    "                         y_valid).sum() / y_valid.numel()\n",
    "base_acc_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_get_drop_acc(pnn, X_valid, y_valid, base_acc_valid, type_fault=1, num_fault_sub_type=[]):\n",
    "    # type of fault: 0 - theta, 1 - act, 2 - neg\n",
    "    # dict_fault_sub_type = {i: [] for i in range(num_fault_sub_type)}\n",
    "    dict_fault_sub_type = {i: [] for i in num_fault_sub_type}\n",
    "    list_sample_fault = []\n",
    "    for layer_i, num_neuron in enumerate(topology[1:]):\n",
    "        # list of faulty layers starting from 0\n",
    "        faulty_layer_list=[layer_i]\n",
    "        for neuron_i in range(num_neuron):\n",
    "            # index of element within the layer\n",
    "            indice_to_modify=neuron_i\n",
    "            # for sub_fault_i in range(num_fault_sub_type):\n",
    "            for sub_fault_i in num_fault_sub_type:\n",
    "                # type of fault within the non-linear circuit\n",
    "                fault_type_non_linear=sub_fault_i\n",
    "                \n",
    "                sample_fault = (faulty_layer_list, type_fault, indice_to_modify, fault_type_non_linear)\n",
    "                list_sample_fault.append(sample_fault)\n",
    "                \n",
    "                pred_valid = pnn(X_valid, faulty_layer_list=faulty_layer_list, type_fault=type_fault, \n",
    "                                indice_to_modify=indice_to_modify, fault_type_non_linear=fault_type_non_linear)[0,0,:,:]\n",
    "\n",
    "                acc_valid = (torch.argmax(pred_valid, dim=1) ==\n",
    "                                        y_valid).sum() / y_valid.numel()\n",
    "                drop_acc = base_acc_valid - acc_valid\n",
    "                dict_fault_sub_type[sub_fault_i].append(drop_acc)\n",
    "                # print(f'layer: {layer_i}, neuron: {neuron_i}, sub_fault: {sub_fault_i}, drop_acc: {drop_acc}')\n",
    "    return dict_fault_sub_type, list_sample_fault\n",
    "\n",
    "\n",
    "def theta_get_drop_acc(pnn, X_valid, y_valid, base_acc_valid, type_fault=0, num_fault_sub_type=2):\n",
    "    # type of fault: 0 - theta, 1 - act, 2 - neg\n",
    "    dict_fault_sub_type = {i: [] for i in range(num_fault_sub_type)}\n",
    "    list_sample_fault = []\n",
    "    for layer_i, _ in enumerate(topology[1:]):\n",
    "        # list of faulty layers starting from 0\n",
    "        faulty_layer_list=[layer_i]\n",
    "        for connection_i in range(torch.prod(torch.tensor(pnn.model[layer_i].theta_.shape))):\n",
    "            # index of element within the layer\n",
    "            indice_to_modify=connection_i\n",
    "            for sub_fault_i in range(num_fault_sub_type):\n",
    "                # type of fault within the non-linear circuit\n",
    "                fault_type_non_linear=sub_fault_i\n",
    "                \n",
    "                sample_fault = (faulty_layer_list, type_fault, indice_to_modify, fault_type_non_linear)\n",
    "                list_sample_fault.append(sample_fault)\n",
    "                \n",
    "                pred_valid = pnn(X_valid, faulty_layer_list=faulty_layer_list, type_fault=type_fault, \n",
    "                                indice_to_modify=indice_to_modify, fault_type_non_linear=fault_type_non_linear)[0,0,:,:]\n",
    "\n",
    "                acc_valid = (torch.argmax(pred_valid, dim=1) ==\n",
    "                                        y_valid).sum() / y_valid.numel()\n",
    "                drop_acc = base_acc_valid - acc_valid\n",
    "                dict_fault_sub_type[sub_fault_i].append(drop_acc)\n",
    "                # print(f'layer: {layer_i}, connection: {connection_i}, sub_fault: {sub_fault_i}, drop_acc: {drop_acc}')\n",
    "    return dict_fault_sub_type, list_sample_fault\n",
    "\n",
    "\n",
    "def inv_get_drop_acc(pnn, X_valid, y_valid, base_acc_valid, type_fault=2, num_fault_sub_type=[]):\n",
    "    # type of fault: 0 - theta, 1 - act, 2 - neg\n",
    "    dict_fault_sub_type = {i: [] for i in num_fault_sub_type}\n",
    "    list_sample_fault = []\n",
    "    for layer_i, _ in enumerate(topology[1:]):\n",
    "        # list of faulty layers starting from 0\n",
    "        faulty_layer_list=[layer_i]\n",
    "        for input_i in range(torch.tensor(pnn.model[layer_i].theta_.shape[0])):\n",
    "            # index of element within the layer\n",
    "            indice_to_modify=input_i\n",
    "            for sub_fault_i in num_fault_sub_type:\n",
    "                # type of fault within the non-linear circuit\n",
    "                fault_type_non_linear=sub_fault_i\n",
    "                \n",
    "                sample_fault = (faulty_layer_list, type_fault, indice_to_modify, fault_type_non_linear)\n",
    "                list_sample_fault.append(sample_fault)\n",
    "                \n",
    "                pred_valid = pnn(X_valid, faulty_layer_list=faulty_layer_list, type_fault=type_fault, \n",
    "                                indice_to_modify=indice_to_modify, fault_type_non_linear=fault_type_non_linear)[0,0,:,:]\n",
    "\n",
    "                acc_valid = (torch.argmax(pred_valid, dim=1) ==\n",
    "                                        y_valid).sum() / y_valid.numel()\n",
    "                drop_acc = base_acc_valid - acc_valid\n",
    "                dict_fault_sub_type[sub_fault_i].append(drop_acc)\n",
    "                # print(f'layer: {layer_i}, connection: {input_i}, sub_fault: {sub_fault_i}, drop_acc: {drop_acc}')\n",
    "    return dict_fault_sub_type, list_sample_fault"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_fault_sub_type, act_list_fault_sample = act_get_drop_acc(pnn, X_valid, y_valid, base_acc_valid, type_fault=1, num_fault_sub_type=range(12))\n",
    "\n",
    "# Define layers and neurons (x-axis)\n",
    "layers_neurons = [f\"L{i}-N{j}\" for i in range(len(topology[1:]) ) for j in range(topology[i+1])]\n",
    "\n",
    "# Define Tanh fault types (y-axis)\n",
    "tanh_faults = [f\"Tanh Fault {i}\" for i in dict_fault_sub_type.keys()]\n",
    "\n",
    "# Simulate accuracy drop data (rows: faults, columns: layer-neurons)\n",
    "accuracy_drop = np.int16(np.array([dict_fault_sub_type[i] for i in dict_fault_sub_type.keys()]) * 100)\n",
    "\n",
    "# Plot the heatmap using Seaborn for annotations\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# Create a figure and axis\n",
    "fig, axs = plt.subplots(3, 1, figsize=(18, 18), gridspec_kw={'height_ratios': [1, 1, 1]})\n",
    "\n",
    "sns.heatmap(accuracy_drop, annot=True, fmt=\"d\", cmap=\"RdYlGn_r\", ax=axs[0], cbar_kws={'label': 'Accuracy Drop (%)'}, xticklabels=layers_neurons, yticklabels=tanh_faults)\n",
    "axs[0].set_title(\"Impact of Tanh Faults on Accuracy Across Layers and Neurons\", fontsize=14)\n",
    "axs[0].set_xlabel(\"Layer-Neuron\", fontsize=12)\n",
    "axs[0].set_ylabel(\"Tanh Fault Types\", fontsize=12)\n",
    "axs[0].set_xticklabels(axs[0].get_xticklabels(),rotation=45, ha=\"right\")\n",
    "\n",
    "# -----------------------------------------\n",
    "\n",
    "dict_fault_sub_type, inv_list_fault_sample = inv_get_drop_acc(pnn, X_valid, y_valid, base_acc_valid, type_fault=2, num_fault_sub_type=range(18))\n",
    "\n",
    "# Define layers and neurons (x-axis)\n",
    "layers_neurons = [f\"L{i}-I{j}\" for i in range(len(topology[:-1]) ) for j in range(pnn.model[i].theta_.shape[0])]\n",
    "\n",
    "# Define Tanh fault types (y-axis)\n",
    "tanh_faults = [f\"INV Fault {i}\" for i in dict_fault_sub_type.keys()]\n",
    "\n",
    "# Simulate accuracy drop data (rows: faults, columns: layer-neurons)\n",
    "accuracy_drop = np.int16(np.array([dict_fault_sub_type[i] for i in dict_fault_sub_type.keys()]) * 100)\n",
    "\n",
    "sns.heatmap(accuracy_drop, annot=True, fmt=\"d\", cmap=\"RdYlGn_r\", ax=axs[1], cbar_kws={'label': 'Accuracy Drop (%)'}, xticklabels=layers_neurons, yticklabels=tanh_faults)\n",
    "axs[1].set_title(\"Impact of Invertor Faults on Accuracy Across Layers and Inputs\", fontsize=14)\n",
    "axs[1].set_xlabel(\"Layer-Inputs\", fontsize=12)\n",
    "axs[1].set_ylabel(\"Invertor Fault Types\", fontsize=12)\n",
    "axs[1].set_xticklabels(axs[1].get_xticklabels(),rotation=45, ha=\"right\")\n",
    "\n",
    "# -----------------------------------------\n",
    "\n",
    "dict_fault_sub_type, theta_list_fault_sample = theta_get_drop_acc(pnn, X_valid, y_valid, base_acc_valid, type_fault=0, num_fault_sub_type=2)\n",
    "\n",
    "# Define layers and neurons (x-axis)\n",
    "layers_neurons = [f\"L{i}-C{j}\" for i in range(len(topology[1:]) ) for j in range(torch.prod(torch.tensor(pnn.model[i].theta_.shape)))]\n",
    "\n",
    "# Define Tanh fault types (y-axis)\n",
    "tanh_faults = [f\"Theta Fault {i}\" for i in dict_fault_sub_type.keys()]\n",
    "\n",
    "# Simulate accuracy drop data (rows: faults, columns: layer-neurons)\n",
    "accuracy_drop = np.int16(np.array([dict_fault_sub_type[i] for i in dict_fault_sub_type.keys()]) * 100)\n",
    "\n",
    "sns.heatmap(accuracy_drop, annot=True, fmt=\"d\", cmap=\"RdYlGn_r\", ax=axs[2], cbar_kws={'label': 'Accuracy Drop (%)'}, xticklabels=layers_neurons, yticklabels=tanh_faults)\n",
    "axs[2].set_title(\"Impact of Theta Faults on Accuracy Across Layers and Connections\", fontsize=14)\n",
    "axs[2].set_xlabel(\"Layer-Connection\", fontsize=12)\n",
    "axs[2].set_ylabel(\"Theta Fault Types\", fontsize=12)\n",
    "axs[2].set_xticklabels(axs[2].get_xticklabels(),rotation=45, ha=\"right\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Tanh Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after clustering\n",
    "# num_fault_sub_type = [2, 6, 12, 0, 1, 3, 4] \n",
    "num_fault_sub_type = np.array([3, 11, 5, 0, 2, 10, 1]) + 1\n",
    "cluster_dict_fault_sub_type, cluster_act_list_fault_sample = act_get_drop_acc(pnn, X_valid, y_valid, base_acc_valid, type_fault=1, num_fault_sub_type=num_fault_sub_type)\n",
    "\n",
    "# Define layers and neurons (x-axis)\n",
    "layers_neurons = [f\"L{i}-N{j}\" for i in range(len(topology[1:]) ) for j in range(topology[i+1])]\n",
    "\n",
    "# Define Tanh fault types (y-axis)\n",
    "tanh_faults = [f\"Tanh Fault {i}\" for i in cluster_dict_fault_sub_type.keys()]\n",
    "\n",
    "# Simulate accuracy drop data (rows: faults, columns: layer-neurons)\n",
    "accuracy_drop = np.int16(np.array([cluster_dict_fault_sub_type[i] for i in cluster_dict_fault_sub_type.keys()]) * 100)\n",
    "\n",
    "# Plot the heatmap using Seaborn for annotations\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# Create a figure and axis\n",
    "fig, axs = plt.subplots(2, 1, figsize=(18, 18), gridspec_kw={'height_ratios': [1, 1]})\n",
    "\n",
    "sns.heatmap(accuracy_drop, annot=True, fmt=\"d\", cmap=\"RdYlGn_r\", ax=axs[0], cbar_kws={'label': 'Accuracy Drop (%)'}, xticklabels=layers_neurons, yticklabels=tanh_faults)\n",
    "axs[0].set_title(\"(After Clustering) Impact of Tanh Faults on Accuracy Across Layers and Neurons\", fontsize=14)\n",
    "axs[0].set_xlabel(\"Layer-Neuron\", fontsize=12)\n",
    "axs[0].set_ylabel(\"Tanh Fault Types\", fontsize=12)\n",
    "axs[0].set_xticklabels(axs[0].get_xticklabels(),rotation=45, ha=\"right\")\n",
    "\n",
    "# -----------------------------------------\n",
    "\n",
    "# before clustering\n",
    "num_fault_sub_type = range(1, 13)\n",
    "all_dict_fault_sub_type, all_act_list_fault_sample = act_get_drop_acc(pnn, X_valid, y_valid, base_acc_valid, type_fault=1, num_fault_sub_type=num_fault_sub_type)\n",
    "\n",
    "# Define layers and neurons (x-axis)\n",
    "layers_neurons = [f\"L{i}-N{j}\" for i in range(len(topology[1:]) ) for j in range(topology[i+1])]\n",
    "\n",
    "# Define Tanh fault types (y-axis)\n",
    "tanh_faults = [f\"Tanh Fault {i}\" for i in all_dict_fault_sub_type.keys()]\n",
    "\n",
    "# Simulate accuracy drop data (rows: faults, columns: layer-neurons)\n",
    "accuracy_drop = np.int16(np.array([all_dict_fault_sub_type[i] for i in all_dict_fault_sub_type.keys()]) * 100)\n",
    "\n",
    "# Plot the heatmap using Seaborn for annotations\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# Create a figure and axis\n",
    "# fig, axs = plt.subplots(3, 1, figsize=(18, 18), gridspec_kw={'height_ratios': [1, 1, 1]})\n",
    "\n",
    "sns.heatmap(accuracy_drop, annot=True, fmt=\"d\", cmap=\"RdYlGn_r\", ax=axs[1], cbar_kws={'label': 'Accuracy Drop (%)'}, xticklabels=layers_neurons, yticklabels=tanh_faults)\n",
    "axs[1].set_title(\"(Before Clustering) Impact of Tanh Faults on Accuracy Across Layers and Neurons\", fontsize=14)\n",
    "axs[1].set_xlabel(\"Layer-Neuron\", fontsize=12)\n",
    "axs[1].set_ylabel(\"Tanh Fault Types\", fontsize=12)\n",
    "axs[1].set_xticklabels(axs[1].get_xticklabels(),rotation=45, ha=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_act_list_fault_sample), len(cluster_act_list_fault_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_get_output_differences(pnn, test_inputs, topology, type_fault=1, num_fault_sub_type=[]):\n",
    "    \"\"\"\n",
    "    Calculate the average output differences caused by faults for each layer and neuron.\n",
    "    \n",
    "    Args:\n",
    "        pnn: The neural network model.\n",
    "        test_inputs: A batch of test inputs (tensor).\n",
    "        topology: List of layer sizes in the network.\n",
    "        type_fault: Type of fault (0 - theta, 1 - act, 2 - neg).\n",
    "        num_fault_sub_type: List of fault sub-types to analyze.\n",
    "\n",
    "    Returns:\n",
    "        dict_fault_sub_type: A dictionary mapping fault sub-types to their impact across neurons.\n",
    "        list_sample_fault: A list of all fault configurations tested.\n",
    "    \"\"\"\n",
    "    # Dictionary to store the impact for each fault sub-type\n",
    "    dict_fault_sub_type = {i: [] for i in num_fault_sub_type}\n",
    "    list_sample_fault = []\n",
    "    active_faults = []\n",
    "    inactive_faults = []\n",
    "\n",
    "    # Loop over all layers and neurons\n",
    "    for layer_i, num_neurons in enumerate(topology[1:]):  # Skip input layer\n",
    "        # List of faulty layers starting from 0\n",
    "        faulty_layer_list = [layer_i]\n",
    "\n",
    "        for neuron_i in range(num_neurons):  # Loop through neurons in the layer\n",
    "            indice_to_modify = neuron_i\n",
    "\n",
    "            for sub_fault_i in num_fault_sub_type:  # Loop through fault sub-types\n",
    "                fault_type_non_linear = sub_fault_i\n",
    "\n",
    "                # Create a fault configuration\n",
    "                sample_fault = (faulty_layer_list, type_fault, indice_to_modify, fault_type_non_linear)\n",
    "                list_sample_fault.append(sample_fault)\n",
    "\n",
    "                # Compute fault-free outputs\n",
    "                output_fault_free = pnn(test_inputs)[0, 0, :, :]\n",
    "\n",
    "                # Compute faulty outputs\n",
    "                output_faulty = pnn(test_inputs, faulty_layer_list=faulty_layer_list, \n",
    "                                    type_fault=type_fault, \n",
    "                                    indice_to_modify=indice_to_modify, \n",
    "                                    fault_type_non_linear=fault_type_non_linear)[0, 0, :, :]\n",
    "\n",
    "                # Calculate the average output difference for this fault\n",
    "                # diff = torch.mean(torch.norm(output_faulty - output_fault_free, dim=1)).item()\n",
    "                diff = torch.nn.functional.mse_loss(output_faulty, output_fault_free).item()\n",
    "\n",
    "                # Store the impact for this fault sub-type\n",
    "                dict_fault_sub_type[sub_fault_i].append(diff)\n",
    "\n",
    "                # Print for debugging\n",
    "                # print(f\"Layer: {layer_i}, Neuron: {neuron_i}, Sub-Fault: {sub_fault_i}, Avg Difference: {diff}\")\n",
    "                \n",
    "                # Sum differences over all test inputs for the fault\n",
    "                sum_diff = torch.sum(torch.abs(output_faulty - output_fault_free)).item()\n",
    "\n",
    "                # Classify faults as active or inactive\n",
    "                if sum_diff > 0:\n",
    "                    active_faults.append(sample_fault)\n",
    "                else:\n",
    "                    inactive_faults.append(sample_fault)\n",
    "\n",
    "    return dict_fault_sub_type, list_sample_fault, active_faults, inactive_faults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize, TwoSlopeNorm\n",
    "\n",
    "# num_fault_sub_type = [2, 6, 12, 0, 1, 3, 4]\n",
    "num_fault_sub_type = np.array([3, 11, 5, 0, 2, 10, 1]) + 1\n",
    "test_input_dim = topology[0]\n",
    "test_inputs = torch.rand(1000, test_input_dim)  # Adjust input dimension \n",
    "    \n",
    "dict_fault_sub_type, list_act_sample_fault, act_active_faults, act_inactive_faults = act_get_output_differences(\n",
    "    pnn=pnn,\n",
    "    test_inputs=test_inputs,\n",
    "    topology=topology,\n",
    "    type_fault=1,\n",
    "    num_fault_sub_type=num_fault_sub_type)\n",
    "\n",
    "# Define layers and neurons (x-axis)\n",
    "layers_neurons = [f\"L{i}-N{j}\" for i in range(len(topology[1:])) for j in range(topology[i+1])]\n",
    "\n",
    "# Define Tanh fault types (y-axis)\n",
    "tanh_faults = [f\"Tanh Fault {i}\" for i in dict_fault_sub_type.keys()]\n",
    "\n",
    "# Simulate output difference data (rows: faults, columns: layer-neurons)\n",
    "output_differences = np.array([dict_fault_sub_type[i] for i in dict_fault_sub_type.keys()])\n",
    "\n",
    "# Apply normalization to make zero values distinctly green\n",
    "norm = TwoSlopeNorm(vmin=0, vcenter=0.01, vmax=np.max(output_differences))\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(\n",
    "    output_differences,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    cmap=\"RdYlGn_r\",  # Diverging colormap\n",
    "    xticklabels=layers_neurons,\n",
    "    yticklabels=tanh_faults,\n",
    "    cbar_kws={'label': 'Output Difference (%)'},\n",
    "    norm=norm  # Use TwoSlopeNorm for distinct green at zero\n",
    ")\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(\"(After Clustering) Impact of Tanh Faults on Output Differences Across Layers and Neurons\", fontsize=16)\n",
    "plt.xlabel(\"Layer-Neuron\", fontsize=14)\n",
    "plt.ylabel(\"Tanh Fault Types\", fontsize=14)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# Adjust layout to fit labels properly\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_act_list_fault_sample), len(act_active_faults), len(act_inactive_faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_active_faults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Invetor Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after clustering\n",
    "num_fault_sub_type = np.array([0, 4, 1, 16, 2, 15, 8, 11, 6]) + 1\n",
    "cluster_dict_fault_sub_type, cluster_inv_list_fault_sample = inv_get_drop_acc(pnn, X_valid, y_valid, base_acc_valid, type_fault=2, num_fault_sub_type=num_fault_sub_type)\n",
    "\n",
    "# Define layers and neurons (x-axis)\n",
    "layers_neurons = [f\"L{i}-N{j}\" for i in range(len(topology[1:]) ) for j in range(topology[i+1])]\n",
    "\n",
    "# Define Tanh fault types (y-axis)\n",
    "tanh_faults = [f\"Tanh Fault {i}\" for i in cluster_dict_fault_sub_type.keys()]\n",
    "\n",
    "# Simulate accuracy drop data (rows: faults, columns: layer-neurons)\n",
    "accuracy_drop = np.int16(np.array([cluster_dict_fault_sub_type[i] for i in cluster_dict_fault_sub_type.keys()]) * 100)\n",
    "\n",
    "# Plot the heatmap using Seaborn for annotations\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# Create a figure and axis\n",
    "fig, axs = plt.subplots(2, 1, figsize=(18, 18), gridspec_kw={'height_ratios': [1, 1]})\n",
    "\n",
    "sns.heatmap(accuracy_drop, annot=True, fmt=\"d\", cmap=\"RdYlGn_r\", ax=axs[0], cbar_kws={'label': 'Accuracy Drop (%)'}, xticklabels=layers_neurons, yticklabels=tanh_faults)\n",
    "axs[0].set_title(\"(After Clustering) Impact of Tanh Faults on Accuracy Across Layers and Neurons\", fontsize=14)\n",
    "axs[0].set_xlabel(\"Layer-Neuron\", fontsize=12)\n",
    "axs[0].set_ylabel(\"Tanh Fault Types\", fontsize=12)\n",
    "axs[0].set_xticklabels(axs[0].get_xticklabels(),rotation=45, ha=\"right\")\n",
    "\n",
    "# -----------------------------------------\n",
    "\n",
    "# before clustering\n",
    "num_fault_sub_type = range(1, 19)\n",
    "all_dict_fault_sub_type, all_inv_list_fault_sample = inv_get_drop_acc(pnn, X_valid, y_valid, base_acc_valid, type_fault=2, num_fault_sub_type=num_fault_sub_type)\n",
    "\n",
    "# Define layers and neurons (x-axis)\n",
    "layers_neurons = [f\"L{i}-N{j}\" for i in range(len(topology[1:]) ) for j in range(topology[i+1])]\n",
    "\n",
    "# Define Tanh fault types (y-axis)\n",
    "tanh_faults = [f\"Tanh Fault {i}\" for i in all_dict_fault_sub_type.keys()]\n",
    "\n",
    "# Simulate accuracy drop data (rows: faults, columns: layer-neurons)\n",
    "accuracy_drop = np.int16(np.array([all_dict_fault_sub_type[i] for i in all_dict_fault_sub_type.keys()]) * 100)\n",
    "\n",
    "# Plot the heatmap using Seaborn for annotations\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# Create a figure and axis\n",
    "# fig, axs = plt.subplots(3, 1, figsize=(18, 18), gridspec_kw={'height_ratios': [1, 1, 1]})\n",
    "\n",
    "sns.heatmap(accuracy_drop, annot=True, fmt=\"d\", cmap=\"RdYlGn_r\", ax=axs[1], cbar_kws={'label': 'Accuracy Drop (%)'}, xticklabels=layers_neurons, yticklabels=tanh_faults)\n",
    "axs[1].set_title(\"(Before Clustering) Impact of Tanh Faults on Accuracy Across Layers and Neurons\", fontsize=14)\n",
    "axs[1].set_xlabel(\"Layer-Neuron\", fontsize=12)\n",
    "axs[1].set_ylabel(\"Tanh Fault Types\", fontsize=12)\n",
    "axs[1].set_xticklabels(axs[1].get_xticklabels(),rotation=45, ha=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_inv_list_fault_sample), len(cluster_inv_list_fault_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_get_output_differences(pnn, test_inputs, topology, type_fault=1, num_fault_sub_type=[]):\n",
    "    \"\"\"\n",
    "    Calculate the average output differences caused by faults for each layer and neuron.\n",
    "    \n",
    "    Args:\n",
    "        pnn: The neural network model.\n",
    "        test_inputs: A batch of test inputs (tensor).\n",
    "        topology: List of layer sizes in the network.\n",
    "        type_fault: Type of fault (0 - theta, 1 - act, 2 - neg).\n",
    "        num_fault_sub_type: List of fault sub-types to analyze.\n",
    "\n",
    "    Returns:\n",
    "        dict_fault_sub_type: A dictionary mapping fault sub-types to their impact across neurons.\n",
    "        list_sample_fault: A list of all fault configurations tested.\n",
    "    \"\"\"\n",
    "    # Dictionary to store the impact for each fault sub-type\n",
    "    dict_fault_sub_type = {i: [] for i in num_fault_sub_type}\n",
    "    list_sample_fault = []\n",
    "    active_faults = []\n",
    "    inactive_faults = []\n",
    "    \n",
    "\n",
    "    # Loop over all layers and neurons\n",
    "    for layer_i, num_neurons in enumerate(topology[1:]):  # Skip input layer\n",
    "        # List of faulty layers starting from 0\n",
    "        faulty_layer_list = [layer_i]\n",
    "\n",
    "        for input_i in range(torch.tensor(pnn.model[layer_i].theta_.shape[0])):\n",
    "            # index of element within the layer\n",
    "            indice_to_modify=input_i\n",
    "\n",
    "            for sub_fault_i in num_fault_sub_type:\n",
    "                # type of fault within the non-linear circuit\n",
    "                fault_type_non_linear=sub_fault_i\n",
    "\n",
    "                # Create a fault configuration\n",
    "                sample_fault = (faulty_layer_list, type_fault, indice_to_modify, fault_type_non_linear)\n",
    "                list_sample_fault.append(sample_fault)\n",
    "\n",
    "                # Compute fault-free outputs\n",
    "                output_fault_free = pnn(test_inputs)[0, 0, :, :]\n",
    "\n",
    "                # Compute faulty outputs\n",
    "                output_faulty = pnn(test_inputs, faulty_layer_list=faulty_layer_list, \n",
    "                                    type_fault=type_fault, \n",
    "                                    indice_to_modify=indice_to_modify, \n",
    "                                    fault_type_non_linear=fault_type_non_linear)[0, 0, :, :]\n",
    "\n",
    "                # Calculate the average output difference for this fault\n",
    "                # diff = torch.mean(torch.norm(output_faulty - output_fault_free, dim=1)).item()\n",
    "                diff = torch.nn.functional.mse_loss(output_faulty, output_fault_free).item()\n",
    "\n",
    "                # Store the impact for this fault sub-type\n",
    "                dict_fault_sub_type[sub_fault_i].append(diff)\n",
    "\n",
    "                # Print for debugging\n",
    "                # print(f\"Layer: {layer_i}, Neuron: {neuron_i}, Sub-Fault: {sub_fault_i}, Avg Difference: {diff}\")\n",
    "                \n",
    "                # Sum differences over all test inputs for the fault\n",
    "                sum_diff = torch.sum(torch.abs(output_faulty - output_fault_free)).item()\n",
    "\n",
    "                # Classify faults as active or inactive\n",
    "                if sum_diff > 0:\n",
    "                    active_faults.append(sample_fault)\n",
    "                else:\n",
    "                    inactive_faults.append(sample_fault)\n",
    "\n",
    "    return dict_fault_sub_type, list_sample_fault, active_faults, inactive_faults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize, TwoSlopeNorm\n",
    "\n",
    "num_fault_sub_type = np.array([0, 4, 1, 16, 2, 15, 8, 11, 6]) + 1\n",
    "test_input_dim = topology[0]\n",
    "test_inputs = torch.rand(1000, test_input_dim)  # Adjust input dimension\n",
    "    \n",
    "dict_fault_sub_type, inv_list_sample_fault, inv_active_faults, inv_inactive_faults = inv_get_output_differences(\n",
    "    pnn=pnn,\n",
    "    test_inputs=test_inputs,\n",
    "    topology=topology,\n",
    "    type_fault=2,\n",
    "    num_fault_sub_type=num_fault_sub_type)\n",
    "\n",
    "# Define layers and neurons (x-axis)\n",
    "layers_neurons = [f\"L{i}-N{j}\" for i in range(len(topology[1:])) for j in range(topology[i+1])]\n",
    "\n",
    "# Define Tanh fault types (y-axis)\n",
    "tanh_faults = [f\"Tanh Fault {i}\" for i in dict_fault_sub_type.keys()]\n",
    "\n",
    "# Simulate output difference data (rows: faults, columns: layer-neurons)\n",
    "output_differences = np.array([dict_fault_sub_type[i] for i in dict_fault_sub_type.keys()])\n",
    "\n",
    "# Apply normalization to make zero values distinctly green\n",
    "norm = TwoSlopeNorm(vmin=0, vcenter=0.01, vmax=np.max(output_differences))\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(\n",
    "    output_differences,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    cmap=\"RdYlGn_r\",  # Diverging colormap\n",
    "    xticklabels=layers_neurons,\n",
    "    yticklabels=tanh_faults,\n",
    "    cbar_kws={'label': 'Output Difference (%)'},\n",
    "    norm=norm  # Use TwoSlopeNorm for distinct green at zero\n",
    ")\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(\"(After Clustering) Impact of Tanh Faults on Output Differences Across Layers and Neurons\", fontsize=16)\n",
    "plt.xlabel(\"Layer-Neuron\", fontsize=14)\n",
    "plt.ylabel(\"Tanh Fault Types\", fontsize=14)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# Adjust layout to fit labels properly\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_inv_list_fault_sample), len(inv_active_faults), len(inv_inactive_faults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize test input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freez the model\n",
    "for param in pnn.parameters():\n",
    "    param.requires_grad = False\n",
    "test_input_dim = topology[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the type of fault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "faulty_layer_list: list of faulty layers for initial stage it has only one element\n",
    "indice_to_modify: An indice to modify, one of the theta, act or neg\n",
    "fault_type_non_linear: type of fault within the non-linear circuit\n",
    "type_fault: 0 - theta, 1 - act, 2 - neg\n",
    "'''\n",
    "# faulty_layer_list = [0]\n",
    "# indice_to_modify = 2\n",
    "# fault_type_non_linear = 4\n",
    "# type_fault = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat a pool of test inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topology, len(act_list_fault_sample), len(inv_list_fault_sample), len(theta_list_fault_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_pool = act_list_fault_sample + inv_list_fault_sample + theta_list_fault_sample\n",
    "len(fault_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "range of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.min(X_valid), torch.max(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes and Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STEMultiClass(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_init, min_value=0.0, max_value=1.0,):\n",
    "        '''\n",
    "        input_init: Initial input to the model\n",
    "        min_value: Minimum value for the input\n",
    "        max_value: Maximum value for the input\n",
    "        faulty_layer_list: list of faulty layers\n",
    "        type_fault: 0 - theta, 1 - act, 2 - neg\n",
    "        indice_to_modify: An indice to modify, one of the theta, act or neg\n",
    "        fault_type_non_linear: type of fault within the non-linear circuit\n",
    "        '''\n",
    "        super().__init__()\n",
    "        # Learnable parameter for the input\n",
    "        self.test_input_ = torch.nn.Parameter(input_init.clone(), requires_grad=True)\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def test_input(self):\n",
    "        # Clamp the test_input_ to the defined range and apply thresholding\n",
    "        clamped_input = self.test_input_.clamp(self.min_value, self.max_value)\n",
    "        # clamped_input[clamped_input.abs() < self.min_value] = 0.0\n",
    "        return clamped_input\n",
    "    \n",
    "    def forward(self, pretrained_model, all_fault_list, selected_faults_indices):\n",
    "        # Apply the STE logic to the clamped and thresholded input\n",
    "        # test_input_with_ste = self.test_input.detach() + self.test_input_ - self.test_input_.detach()\n",
    "        \n",
    "\n",
    "        # Forward pass through the faulty model\n",
    "        # faulty_output_list = [pretrained_model(test_input_with_ste, *all_fault_list[index_])[0, 0, :, :] for index_ in selected_faults_indices]\n",
    "        faulty_output = pretrained_model(self.test_input, *all_fault_list[selected_faults_indices[0]])[0, 0, :, :]\n",
    "        # faulty_output = pretrained_model(\n",
    "        #         test_input_with_ste,\n",
    "        #         faulty_layer_list=self.faulty_layer_list,\n",
    "        #         type_fault=self.type_fault,\n",
    "        #         indice_to_modify=self.indice_to_modify,\n",
    "        #         fault_type_non_linear=self.fault_type_non_linear\n",
    "        #     )[0, 0, :, :]  # Adjust slicing as necessary\n",
    "            \n",
    "        # Forward pass through the fault-free model\n",
    "        fault_free_output = pretrained_model(\n",
    "                self.test_input,\n",
    "                )[0, 0, :, :]  # Adjust slicing as necessary\n",
    "            \n",
    "        return faulty_output, fault_free_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse_loss(faulty_output, fault_free_output):\n",
    "    print(faulty_output, fault_free_output)\n",
    "    faulty_probs = torch.softmax(faulty_output, dim=0)\n",
    "    fault_free_probs = torch.softmax(fault_free_output, dim=0)                   \n",
    "    \n",
    "    # Compute MSE loss\n",
    "    loss = torch.nn.functional.mse_loss(faulty_probs, fault_free_probs)\n",
    "    return -loss  # Negative to maximize difference\n",
    "\n",
    "def compute_cl_lass(faulty_output, fault_free_output):\n",
    "    faulty_probs = torch.softmax(faulty_output, dim=0)\n",
    "    fault_free_probs = torch.softmax(fault_free_output, dim=0)\n",
    "    loss = torch.nn.functional.cross_entropy(faulty_probs, fault_free_probs)\n",
    "    return -loss\n",
    "\n",
    "def compute_total_loss(fault_free_output, faulty_outputs):\n",
    "    total_loss = 0.0\n",
    "    for idx, faulty_output in enumerate(faulty_outputs):\n",
    "        loss = compute_mse_loss(faulty_output, fault_free_output)\n",
    "        total_loss += loss\n",
    "    return total_loss\n",
    "\n",
    "def compute_classification_loss(faulty_output, fault_free_output):\n",
    "    \"\"\"\n",
    "    Computes classification loss based on class prediction differences.\n",
    "    Loss is 0 if classes are the same; otherwise, 1 (to maximize difference).\n",
    "    \"\"\"\n",
    "    faulty_probs = torch.softmax(faulty_output, dim=0)\n",
    "    fault_free_probs = torch.softmax(fault_free_output, dim=0)\n",
    "    \n",
    "    # Compare predicted classes\n",
    "    class_faulty = torch.argmax(faulty_probs)\n",
    "    class_fault_free = torch.argmax(fault_free_probs)\n",
    "    \n",
    "    # Loss is 1 if classes differ, 0 otherwise\n",
    "    loss = 1.0 if class_faulty != class_fault_free else 0.0\n",
    "    return loss\n",
    "\n",
    "def compute_combined_loss(fault_free_output, faulty_outputs, alpha=0.7, beta=0.3):\n",
    "    \"\"\"\n",
    "    Computes the total loss combining MSE difference and classification coverage.\n",
    "    Args:\n",
    "        fault_free_output: Output of the fault-free model.\n",
    "        faulty_outputs: List of outputs from the faulty models.\n",
    "        alpha: Weight for MSE loss component.\n",
    "        beta: Weight for classification coverage loss component.\n",
    "    \"\"\"\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for faulty_output in faulty_outputs:\n",
    "        # Difference Metric (MSE Loss)\n",
    "        difference_loss = torch.nn.functional.mse_loss(faulty_output, fault_free_output)\n",
    "        \n",
    "        # Classification-Based Coverage Metric\n",
    "        classification_loss = compute_classification_loss(faulty_output, fault_free_output)\n",
    "        \n",
    "        # Combined Loss (Weighted Sum)\n",
    "        total_loss += alpha * difference_loss + beta * classification_loss  # Subtract coverage loss to maximize it\n",
    "    \n",
    "    return - total_loss\n",
    "\n",
    "def compute_kl_loss(faulty_output, fault_free_output):\n",
    "    # Compute probabilities\n",
    "    faulty_probs = torch.nn.functional.softmax(faulty_output, dim=1)\n",
    "    fault_free_probs = torch.nn.functional.softmax(fault_free_output, dim=1)\n",
    "    \n",
    "    # Compute log probabilities\n",
    "    fault_free_log_probs = torch.log(fault_free_probs + 1e-10)\n",
    "    \n",
    "    # Compute KL divergence\n",
    "    kl_loss = torch.nn.functional.kl_div(\n",
    "        input=fault_free_log_probs,\n",
    "        target=faulty_probs,\n",
    "        reduction='batchmean'\n",
    "    )\n",
    "    \n",
    "    return kl_loss\n",
    "\n",
    "def compute_symmetric_kl_loss(faulty_output, fault_free_output):\n",
    "    # Compute probabilities\n",
    "    faulty_probs = torch.nn.functional.softmax(faulty_output, dim=1)\n",
    "    fault_free_probs = torch.nn.functional.softmax(fault_free_output, dim=1)\n",
    "    \n",
    "    # Compute log probabilities\n",
    "    faulty_log_probs = torch.log(faulty_probs + 1e-10)\n",
    "    fault_free_log_probs = torch.log(fault_free_probs + 1e-10)\n",
    "    \n",
    "    # Compute KL divergences\n",
    "    kl_loss_1 = torch.nn.functional.kl_div(fault_free_log_probs, faulty_probs, reduction='batchmean')\n",
    "    kl_loss_2 = torch.nn.functional.kl_div(faulty_log_probs, fault_free_probs, reduction='batchmean')\n",
    "    \n",
    "    # Symmetric KL divergence\n",
    "    symmetric_kl_loss = kl_loss_1 + kl_loss_2\n",
    "    \n",
    "    return symmetric_kl_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_difference_metric(faulty_output, fault_free_output):\n",
    "    # Compute MSE difference\n",
    "    mse_differece = torch.nn.functional.mse_loss(faulty_output, fault_free_output)\n",
    "    \n",
    "    faulty_class = torch.argmax(torch.nn.functional.softmax(faulty_output.detach(), dim=1)).numpy()  # Convert to numpy for readability\n",
    "    fault_free_class = torch.argmax(torch.nn.functional.softmax(fault_free_output.detach(), dim=1)).numpy()  # Convert to numpy for readability\n",
    "    equal = int(faulty_class != fault_free_class)\n",
    "    \n",
    "    return mse_differece, equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Population as inital test inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import random\n",
    "\n",
    "# # act_list_fault_temp = act_list_fault_sample[:20]\n",
    "# act_list_fault_temp = active_faults\n",
    "\n",
    "# # Evolutionary algorithm parameters\n",
    "# population_size = len(act_list_fault_temp)+20\n",
    "# num_generations = 50\n",
    "# mutation_rate = 0.5\n",
    "# crossover_rate = 0.7\n",
    "# test_input_dim = topology[0]  # Dimensionality of the test input\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# # Weights for fitness function\n",
    "# alpha = 0.5  # Weight for difference metric\n",
    "# beta = 0.5   # Weight for coverage metric\n",
    "\n",
    "# # Initialize population\n",
    "# population = [torch.randn(test_input_dim, device=device, requires_grad=False) for _ in range(population_size)]\n",
    "\n",
    "# # Fitness function (unchanged from previous implementation)\n",
    "# def evaluate_fitness(test_input, pnn, act_list_fault_temp):\n",
    "#     fault_free_output = pnn(test_input)[0, 0, :, :]\n",
    "#     # fault_free_probs = torch.softmax(fault_free_output, dim=0)\n",
    "\n",
    "#     faulty_outputs = [pnn(test_input, *fault)[0, 0, :, :] for fault in act_list_fault_temp]\n",
    "#     # faulty_probs_list = [torch.softmax(output, dim=0) for output in faulty_outputs]\n",
    "\n",
    "#     differences = [compute_difference_metric(faulty_output, fault_free_output)[0] for faulty_output in faulty_outputs]\n",
    "#     difference_metric = sum(differences)\n",
    "    \n",
    "#     coverages = [compute_difference_metric(faulty_output, fault_free_output)[1] for faulty_output in faulty_outputs]\n",
    "#     coverage_metric = sum(coverages)\n",
    "\n",
    "#     # coverage_metric = sum(\n",
    "#     #     1 for faulty_probs in faulty_probs_list\n",
    "#     #     if torch.argmax(fault_free_probs) != torch.argmax(faulty_probs)\n",
    "#     # )\n",
    "\n",
    "#     fitness = alpha * difference_metric + beta * coverage_metric\n",
    "#     return fitness, coverage_metric\n",
    "\n",
    "# # Initialize population (constrained to [0, 1])\n",
    "# population = [torch.rand(test_input_dim, device=device) for _ in range(population_size)]\n",
    "\n",
    "# # Selection (Tournament Selection)\n",
    "# def select_parents(population, fitnesses, tournament_size=3):\n",
    "#     \"\"\"Select parents using tournament selection.\"\"\"\n",
    "#     selected = []\n",
    "#     for _ in range(2):  # Select two parents\n",
    "#         tournament = random.sample(list(zip(population, fitnesses)), tournament_size)\n",
    "#         winner = max(tournament, key=lambda x: x[1])  # Select the one with the highest fitness\n",
    "#         selected.append(winner[0])\n",
    "#     return selected\n",
    "\n",
    "# # Crossover with Range Constraint\n",
    "# def crossover(parent1, parent2, crossover_rate=0.7):\n",
    "#     \"\"\"Perform crossover between two parents and clamp offspring to [0, 1].\"\"\"\n",
    "#     if random.random() < crossover_rate:\n",
    "#         point = random.randint(1, test_input_dim - 1)\n",
    "#         offspring1 = torch.cat([parent1[:point], parent2[point:]])\n",
    "#         offspring2 = torch.cat([parent2[:point], parent1[point:]])\n",
    "#         return offspring1.clamp(0, 1), offspring2.clamp(0, 1)\n",
    "#     return parent1.clone(), parent2.clone()\n",
    "\n",
    "# # Mutation with Clamping\n",
    "# def mutate(individual, mutation_rate=0.1):\n",
    "#     \"\"\"Apply mutations and clamp individual to [0, 1].\"\"\"\n",
    "#     if random.random() < mutation_rate:\n",
    "#         mutation = torch.randn_like(individual) * 0.1  # Scale mutation strength\n",
    "#         individual += mutation\n",
    "#         individual = individual.clamp(0, 1)\n",
    "#     return individual\n",
    "\n",
    "# # num_elites = 2  # Number of elite individuals to retain\n",
    "# # Evolutionary Algorithm\n",
    "# for generation in range(num_generations):\n",
    "#     fitnesses = []\n",
    "#     coverage_metrics = []\n",
    "#     for individual in population:\n",
    "#         fitness, coverage = evaluate_fitness(individual, pnn, act_list_fault_temp)\n",
    "#         fitnesses.append(fitness)\n",
    "#         coverage_metrics.append(coverage)\n",
    "\n",
    "#     best_fitness = max(fitnesses)\n",
    "#     best_individual = population[fitnesses.index(best_fitness)]\n",
    "#     print(f\"Generation {generation}, Best Fitness: {best_fitness}, Coverage: {max(coverage_metrics)}\")\n",
    "    \n",
    "#     # # Retain elites\n",
    "#     # elites = sorted(zip(population, fitnesses), key=lambda x: x[1], reverse=True)[:num_elites]\n",
    "#     # elite_individuals = [elite[0] for elite in elites]\n",
    "\n",
    "#     # Selection and Reproduction\n",
    "#     new_population = []\n",
    "#     for _ in range((population_size) // 2):  # Each loop creates two offspring\n",
    "#         parent1, parent2 = select_parents(population, fitnesses)\n",
    "#         offspring1, offspring2 = crossover(parent1, parent2, crossover_rate)\n",
    "#         offspring1 = mutate(offspring1, mutation_rate)\n",
    "#         offspring2 = mutate(offspring2, mutation_rate)\n",
    "#         new_population.extend([offspring1, offspring2])\n",
    "        \n",
    "#     # Add elites back into the population\n",
    "#     # population = new_population + elite_individuals\n",
    "\n",
    "#     # Replace population with new individuals\n",
    "#     population = new_population\n",
    "\n",
    "# # Output the best test input pool\n",
    "# optimized_test_input_pool = population\n",
    "# print(\"Optimized Test Input Pool:\", optimized_test_input_pool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering Test Compaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu'\n",
    "# covered_faults = set()\n",
    "# uncovered_faults = set()\n",
    "# # act_list_fault_temp = act_list_fault_sample[:20]\n",
    "# act_list_fault_temp = active_faults\n",
    "\n",
    "# # act_test_input_pool = torch.randn((len(act_list_fault_temp), topology[0]), requires_grad=False).to(device)\n",
    "# act_test_input_pool = population\n",
    "\n",
    "# # Batch process all fault-free outputs\n",
    "# # output_fault_free_list = pnn(act_test_input_pool)[0, 0, :, :]\n",
    " \n",
    "# multi_fault = True   \n",
    "# while (len(covered_faults)+len(uncovered_faults)) != len(act_list_fault_temp):\n",
    "    \n",
    "#     print(f\"Covered Faults: {covered_faults}\")\n",
    "#     test_input_metrics = []\n",
    "#     for test_input_i, test_input in enumerate(act_test_input_pool):\n",
    "#         # output_fault_free = output_fault_free_list[test_input_i: test_input_i+1]\n",
    "#         output_fault_free = pnn(test_input)[0, 0, :, :]\n",
    "#         output_faulty_list = [pnn(test_input,*fault)[0, 0, :, :] for fault in act_list_fault_temp]\n",
    "        \n",
    "#         differences = [compute_difference_metric(output, output_fault_free)[0] if (i_out not in covered_faults) else None for i_out, output in enumerate(output_faulty_list)]\n",
    "#         equals = [compute_difference_metric(output, output_fault_free)[1] if (i_out not in covered_faults) else 0 for i_out, output in enumerate(output_faulty_list)]\n",
    "        \n",
    "#         # print('differences: ', differences)\n",
    "#         # print('equals: ', equals)\n",
    "        \n",
    "#         total_difference = sum(diff for diff in differences if diff is not None)\n",
    "#         total_equal = sum(equals)\n",
    "#         indices = (torch.nonzero(torch.tensor(equals) == 1).squeeze()).tolist()\n",
    "#         # print(f\"indices: {indices}\")\n",
    "#             # coverage_count = sum(1 for diff in differences if diff > threshold)\n",
    "#         test_input_metrics.append((test_input, total_difference, total_equal, indices))\n",
    "        \n",
    "#     # Select the best test input using heapq for efficiency\n",
    "#     best_test_input_data = heapq.nlargest(1, test_input_metrics, key=lambda x: (x[2], x[1]))[0]\n",
    "#     best_test_input, selected_faults = best_test_input_data[0], best_test_input_data[3]\n",
    "#     multi_fault = True if len(selected_faults) > 1 else False\n",
    "    \n",
    "#     if len(selected_faults) == 0:\n",
    "#         for i_fault, fault in enumerate(act_list_fault_temp):\n",
    "#             if i_fault not in covered_faults:\n",
    "#                 diff = -float('inf')\n",
    "#                 best_equal = 0\n",
    "#                 for test_input_i, test_input in enumerate(population):\n",
    "#                     # output_fault_free = output_fault_free_list[test_input_i: test_input_i+1]\n",
    "#                     output_fault_free = pnn(test_input)[0, 0, :, :]\n",
    "#                     output_faulty = pnn(test_input,*fault)[0, 0, :, :]\n",
    "#                     differences = compute_difference_metric(output_faulty, output_fault_free)[0]\n",
    "#                     equals = compute_difference_metric(output_faulty, output_fault_free)[1]\n",
    "#                     if best_equal < equals:\n",
    "#                         best_equal = equals\n",
    "#                         diff = differences\n",
    "#                         best_test_input = test_input\n",
    "#                     if differences > diff and best_equal == equals:\n",
    "#                         diff = differences\n",
    "#                         best_test_input = test_input\n",
    "#                     print(f\"fault: {i_fault}, differences: {differences}, equals: {equals}\")\n",
    "#                 if diff==0.0:\n",
    "#                     uncovered_faults.add(i_fault)\n",
    "#                 else:\n",
    "#                     selected_faults = [i_fault]\n",
    "#                     break\n",
    "#     print(f\"selected_faults\", selected_faults)\n",
    "    \n",
    "#     if len(selected_faults) == 0:\n",
    "#         break\n",
    "    \n",
    "#     # Optimize the best test input ----------------------------------------------\n",
    "#     # Define fault-free and faulty models\n",
    "#     ste_module = STEMultiClass(best_test_input, min_value=0.0, max_value=1.0)\n",
    "\n",
    "#     # Define the optimizer for input optimization\n",
    "#    # Initialize optimizer and scheduler\n",
    "#     optimizer = optim.Adam([ste_module.test_input_], lr=0.001)\n",
    "#     # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "#     num_epochs = 100\n",
    "#     best_loss = float('inf')\n",
    "#     patience = 10\n",
    "#     # counter = 0\n",
    "#     min_delta = 1e-6\n",
    "    \n",
    "#     # Regularization coefficient\n",
    "#     regularization_coeff = 1e-4\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         optimizer.zero_grad()\n",
    "#         faulty_output_list, fault_free_output = ste_module(pnn, act_list_fault_temp, selected_faults)\n",
    "#         # Compute primary loss\n",
    "#         # primary_loss = compute_total_loss(fault_free_output, faulty_output_list)\n",
    "\n",
    "#         # Add regularization term to the loss\n",
    "#         # reg_term = regularization_coeff * torch.norm(ste_module.test_input_)\n",
    "#         # loss = primary_loss + reg_term\n",
    "#         # loss = compute_total_loss(fault_free_output, faulty_output_list)\n",
    "#         loss = compute_combined_loss(fault_free_output, faulty_output_list, alpha=0.2, beta=0.8)\n",
    "#         if len(selected_faults) == 1:\n",
    "#             print('fault free output: ', fault_free_output, faulty_output_list)\n",
    "#         # assert ste_module.test_input_.requires_grad, \"The gradient is not being tracked for the test input.\"\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         # Adjust learning rate based on loss\n",
    "#         # scheduler.step(loss.item())\n",
    "\n",
    "#         if loss.item() < best_loss - min_delta:\n",
    "#             best_loss = loss.item()\n",
    "#             counter = 0\n",
    "#         else:\n",
    "#             counter += 1\n",
    "        \n",
    "#         if counter >= patience:\n",
    "#             print(f\"Early stopping at epoch {epoch}\")\n",
    "#             break\n",
    "\n",
    "#         if epoch % 10 == 0:\n",
    "#             print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "#     # Checking fault-free and faulty outputs with the optimized test input\n",
    "\n",
    "#     # Ensure the models are in evaluation mode\n",
    "#     ste_module.eval()\n",
    "\n",
    "#     optimized_test_input = ste_module.test_input\n",
    "#     output_fault_free = pnn(optimized_test_input)[0, 0, :, :]\n",
    "#     output_faulty_list = [pnn(optimized_test_input,*act_list_fault_temp[i])[0, 0, :, :] for i in selected_faults]\n",
    "\n",
    "#     print(\"Fault-Free Output:\", torch.argmax(nn.functional.softmax(output_fault_free.detach(), dim=1)).numpy())  # Convert to numpy for readability\n",
    "#     for output in output_faulty_list:\n",
    "#         print(\"Faulty Output:\", torch.argmax(nn.functional.softmax(output.detach(), dim=1)).numpy())  # Convert to numpy for readability\n",
    "\n",
    "        \n",
    "#     differences = [compute_difference_metric(output, output_fault_free)[0] for output in output_faulty_list]\n",
    "#     equals_i = [fault_i for fault_i, output in zip(selected_faults, output_faulty_list) if compute_difference_metric(output, output_fault_free)[1] == 1]\n",
    "#     total_difference = sum(differences)\n",
    "#     if len(equals_i) == 0 and multi_fault:\n",
    "#         # save the initial test input\n",
    "#         covered_faults.update(selected_faults)\n",
    "#     elif len(equals_i) < len(selected_faults) and multi_fault:\n",
    "#         # save the optimized test input\n",
    "#         covered_faults.update(selected_faults)\n",
    "#     else:\n",
    "#         covered_faults.update(equals_i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Inactive Faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_active_faults(cluster_list_fault_sample, batch_size=100):\n",
    "    threshold = 0  # Define a threshold for significant output differences\n",
    "    active_cluster_list_fault_sample = []\n",
    "    test_input_dim = topology[0]\n",
    "    \n",
    "    # Generate a batch of random test inputs (all at once for efficiency)\n",
    "    test_inputs = torch.rand(batch_size, test_input_dim)  # Shape: (batch_size, input_dim)\n",
    "    \n",
    "    # Process faults in batches to avoid Python loops\n",
    "    for fault in cluster_list_fault_sample:\n",
    "        # Compute fault-free and faulty outputs for all test inputs\n",
    "        output_fault_free = pnn(test_inputs)[0, 0, :, :]  # Fault-free outputs\n",
    "        output_faulty = pnn(test_inputs, *fault)[0, 0, :, :]  # Faulty outputs\n",
    "\n",
    "        # Compute differences using MSE loss for all test inputs in the batch\n",
    "        differences = torch.nn.functional.mse_loss(output_faulty, output_fault_free, reduction=\"none\").mean(dim=1)\n",
    "        \n",
    "        # Check if the average difference exceeds the threshold\n",
    "        if differences.mean().item() > threshold:\n",
    "            active_cluster_list_fault_sample.append(fault)\n",
    "\n",
    "    return active_cluster_list_fault_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_cluster_act_list_fault_sample = extract_active_faults(cluster_act_list_fault_sample)\n",
    "active_cluster_inv_list_fault_sample = extract_active_faults(cluster_inv_list_fault_sample)\n",
    "active_cluster_theta_list_fault_sample = extract_active_faults(theta_list_fault_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cluster_act_list_fault_sample), len(active_cluster_act_list_fault_sample), len(cluster_inv_list_fault_sample), len(active_cluster_inv_list_fault_sample), len(theta_list_fault_sample), len(active_cluster_theta_list_fault_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_list_fault_sample = active_cluster_act_list_fault_sample + active_cluster_inv_list_fault_sample + active_cluster_theta_list_fault_sample\n",
    "len(active_list_fault_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(active_list_fault_sample), len(cluster_act_list_fault_sample+cluster_inv_list_fault_sample+theta_list_fault_sample), len(all_act_list_fault_sample+all_inv_list_fault_sample+theta_list_fault_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3, 11, 5, 0, 2, 10, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverage_faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_list_fault_sample[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_input_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Forward pass through fault-free and faulty models\n",
    "# layer, type, neruon, subtype = active_list_fault_sample[14]\n",
    "# temp_fault = (layer, type, neruon, 10)\n",
    "# fault_free_output = pnn(test_input_list[14])[0, 0, :, :]  # Fault-free model\n",
    "# faulty_output = pnn(test_input_list[14], *temp_fault)[0, 0, :, :]  # Faulty model\n",
    "\n",
    "# fault_free_probs = torch.softmax(fault_free_output, dim=1)  # Probabilities\n",
    "\n",
    "# # Evaluate progress\n",
    "# faulty_class = torch.argmax(torch.softmax(faulty_output, dim=1).detach(), dim=1).item()\n",
    "# fault_free_class = torch.argmax(fault_free_probs.detach(), dim=1).item()\n",
    "\n",
    "# faulty_class, fault_free_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Forward pass through fault-free and faulty models\n",
    "# layer, type, neruon, subtype = active_list_fault_sample[14]\n",
    "# temp_fault = (layer, type, neruon, 10)\n",
    "# fault_free_output = pnn(test_input_list[14])[0, 0, :, :]  # Fault-free model\n",
    "# faulty_output = pnn(test_input_list[14], *temp_fault)[0, 0, :, :]  # Faulty model\n",
    "\n",
    "# fault_free_probs = torch.softmax(fault_free_output, dim=1)  # Probabilities\n",
    "\n",
    "# # Evaluate progress\n",
    "# faulty_class = torch.argmax(torch.softmax(faulty_output, dim=1).detach(), dim=1).item()\n",
    "# fault_free_class = torch.argmax(fault_free_probs.detach(), dim=1).item()\n",
    "\n",
    "# faulty_class, fault_free_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Forward pass through fault-free and faulty models\n",
    "# layer, type, neruon, subtype = active_list_fault_sample[0]\n",
    "# # temp_fault = (layer, type, neruon, 10)\n",
    "# fault_free_output = pnn(test_input_list[0])[0, 0, :, :]  # Fault-free model\n",
    "# faulty_output = pnn(test_input_list[0], *active_list_fault_sample[0])[0, 0, :, :]  # Faulty model\n",
    "\n",
    "# fault_free_probs = torch.softmax(fault_free_output, dim=1)  # Probabilities\n",
    "\n",
    "# # Evaluate progress\n",
    "# faulty_class = torch.argmax(torch.softmax(faulty_output, dim=1).detach(), dim=1).item()\n",
    "# fault_free_class = torch.argmax(fault_free_probs.detach(), dim=1).item()\n",
    "\n",
    "# faulty_class, fault_free_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the Best Test Input for Each Fault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "random_search_covered_faults = set()\n",
    "random_search_test_input = torch.zeros((len(active_list_fault_sample), 1, test_input_dim), requires_grad=False)\n",
    "\n",
    "# Iterate over all faults\n",
    "for fault_idx, fault in enumerate(active_list_fault_sample):\n",
    "    # Generate a random pool of test inputs\n",
    "    test_input_pool = torch.rand((100, 1, test_input_dim), requires_grad=False)  # Pool size set to 100 for efficiency\n",
    "\n",
    "    # Compute fault-free and faulty outputs for all test inputs\n",
    "    output_fault_free = pnn(test_input_pool[:, 0, :])[0, 0, :, :]  # Fault-free output\n",
    "    output_faulty = pnn(test_input_pool[:, 0, :], *fault)[0, 0, :, :]  # Faulty output\n",
    "\n",
    "    # Apply softmax to convert logits to probabilities\n",
    "    output_fault_free_probs = F.softmax(output_fault_free, dim=1)  # Shape: (batch_size, num_classes)\n",
    "    output_faulty_probs = F.softmax(output_faulty, dim=1)\n",
    "\n",
    "    # Compute Cross-Entropy Loss\n",
    "    # Comparing fault-free probabilities as the target to the faulty probabilities\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')  # 'none' computes loss for each input individually\n",
    "    loss_per_test_input = criterion(output_faulty_probs, output_fault_free_probs.argmax(dim=1))  # Shape: (batch_size,)\n",
    "\n",
    "    # Identify the best test input (highest loss)\n",
    "    best_test_input_index = torch.argmax(loss_per_test_input).item()\n",
    "    best_test_input = test_input_pool[best_test_input_index]\n",
    "\n",
    "    # Evaluate the class predictions for the fault-free and faulty outputs\n",
    "    fault_free_class = output_fault_free_probs[best_test_input_index].argmax().item()\n",
    "    faulty_class = output_faulty_probs[best_test_input_index].argmax().item()\n",
    "\n",
    "    # Check if the fault causes a class mismatch\n",
    "    if fault_free_class != faulty_class:\n",
    "        random_search_covered_faults.add(fault_idx)\n",
    "        random_search_test_input[fault_idx] = best_test_input  # Save the test input that covers this fault\n",
    "\n",
    "print(\"Covered Faults:\", len(random_search_covered_faults))\n",
    "print(\"Test Coverage:\", len(random_search_covered_faults) / len(active_list_fault_sample))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Test Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "list_fault_temp = active_list_fault_sample\n",
    "\n",
    "coverage_faults = set()\n",
    "test_input_list = torch.zeros((len(list_fault_temp), 1, test_input_dim), requires_grad=False)\n",
    "test_coverage = 0\n",
    "\n",
    "patience_outer = 10\n",
    "no_improve_counter_outer = 0\n",
    "\n",
    "while no_improve_counter_outer < patience_outer:\n",
    "    \n",
    "    # Iterate over all faults\n",
    "    for i_fault in range(len(list_fault_temp)):\n",
    "        \n",
    "        if i_fault in coverage_faults:\n",
    "            continue\n",
    "        \n",
    "        # Generate a random pool of test inputs\n",
    "        test_input_pool = torch.rand((100, 1, test_input_dim), requires_grad=False)  # Pool size set to 100\n",
    "\n",
    "        # Define CrossEntropyLoss\n",
    "        criterion = torch.nn.CrossEntropyLoss(reduction='none')  # Compute loss for each input in the pool\n",
    "\n",
    "        # Compute fault-free and faulty outputs for all test inputs\n",
    "        output_fault_free = pnn(test_input_pool[:, 0, :])[0, 0, :, :]  # Fault-free output\n",
    "        output_faulty = pnn(test_input_pool[:, 0, :], *list_fault_temp[i_fault])[0, 0, :, :]  # Faulty output\n",
    "\n",
    "        # Apply softmax to convert logits to probabilities\n",
    "        output_fault_free_probs = F.softmax(output_fault_free, dim=1)\n",
    "        output_faulty_probs = F.softmax(output_faulty, dim=1)\n",
    "\n",
    "        # Compute Cross-Entropy Loss\n",
    "        loss_per_test_input = criterion(output_faulty_probs, output_fault_free_probs.argmax(dim=1))  # Loss for each input\n",
    "\n",
    "        # Identify the best test input (highest loss)\n",
    "        best_test_input_index = torch.argmax(loss_per_test_input).item()\n",
    "        \n",
    "        # Initialize test input and optimizer\n",
    "        test_input = test_input_pool[best_test_input_index].clone().detach().requires_grad_(True)\n",
    "        optimizer = optim.Adam([test_input], lr=0.01)\n",
    "        loss_fn = torch.nn.KLDivLoss(reduction='batchmean')  # KL divergence expects log probabilities\n",
    "        \n",
    "        num_epochs = 200\n",
    "        early_stopping_patience = 50\n",
    "        best_loss = float('inf')\n",
    "        no_improvement_epochs = 0  # Counter for early stopping\n",
    "        \n",
    "        # Training loop with early stopping\n",
    "        for epoch in range(num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass through fault-free and faulty models\n",
    "            fault_free_output = pnn(test_input)[0, 0, :, :]  # Fault-free model\n",
    "            faulty_output = pnn(test_input, *list_fault_temp[i_fault])[0, 0, :, :]  # Faulty model\n",
    "\n",
    "            # Apply softmax and log for KL divergence\n",
    "            faulty_probs = torch.log_softmax(faulty_output, dim=1)  # Log probabilities\n",
    "            fault_free_probs = torch.softmax(fault_free_output, dim=1)  # Probabilities\n",
    "\n",
    "            # Compute KL divergence loss\n",
    "            loss_value = -loss_fn(faulty_probs, fault_free_probs)  # Negate to maximize difference\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp test input to valid range [0, 1]\n",
    "            test_input.data.clamp_(0, 1)\n",
    "\n",
    "            # Evaluate progress\n",
    "            faulty_class = torch.argmax(faulty_output, dim=1).item()\n",
    "            fault_free_class = torch.argmax(fault_free_probs.detach(), dim=1).item()\n",
    "\n",
    "            if loss_value.item() < best_loss:  # Improvement threshold\n",
    "                best_loss = loss_value.item()\n",
    "                no_improvement_epochs = 0  # Reset early stopping counter\n",
    "                if faulty_class != fault_free_class:\n",
    "                    test_input_list[i_fault] = test_input.clone().detach()\n",
    "                    coverage_faults.add(i_fault)\n",
    "            else:\n",
    "                no_improvement_epochs += 1\n",
    "\n",
    "            # Early stopping check\n",
    "            if no_improvement_epochs >= early_stopping_patience:\n",
    "                print(f\"Early stopping at epoch {epoch} for fault {i_fault}\")\n",
    "                break\n",
    "\n",
    "            # Print progress every 10 epochs\n",
    "            if epoch % 50 == 0:\n",
    "                print(f\"Fault: {i_fault}, Epoch: {epoch}\")\n",
    "                print(\"Fault-Free Output:\", fault_free_class)\n",
    "                print(\"Faulty Output:\", faulty_class)\n",
    "    temp_test_coverage = len(coverage_faults) / len(list_fault_temp) \n",
    "    print(f\"Test Coverage: {test_coverage * 100:.2f}%\")\n",
    "    if temp_test_coverage == test_coverage:\n",
    "        no_improve_counter_outer += 1\n",
    "    else:\n",
    "        no_improve_counter_outer = 0\n",
    "        test_coverage = temp_test_coverage\n",
    "\n",
    "# Print final results\n",
    "print(\"Covered Faults:\", coverage_faults)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Constants\n",
    "POOL_SIZE = 5\n",
    "MAX_EPOCHS = 200\n",
    "EARLY_STOPPING_PATIENCE = 20\n",
    "OUTER_PATIENCE = 5\n",
    "ALPHA = 0.3  # Weighting factor for KL and CE losses\n",
    "\n",
    "list_fault_temp = active_list_fault_sample\n",
    "coverage_faults = set()\n",
    "test_input_list = torch.zeros((len(list_fault_temp), 1, test_input_dim), requires_grad=False)\n",
    "\n",
    "test_coverage = 0\n",
    "no_improve_counter_outer = 0\n",
    "\n",
    "def symmetric_kl_divergence(fault_free_logits, faulty_logits):\n",
    "    fault_free_probs = F.softmax(fault_free_logits, dim=1)\n",
    "    faulty_probs = F.softmax(faulty_logits, dim=1)\n",
    "    kl_1 = F.kl_div(F.log_softmax(fault_free_logits, dim=1), faulty_probs, reduction=\"batchmean\")\n",
    "    kl_2 = F.kl_div(F.log_softmax(faulty_logits, dim=1), fault_free_probs, reduction=\"batchmean\")\n",
    "    return 0.5 * (kl_1 + kl_2)\n",
    "\n",
    "def symmetric_cross_entropy(fault_free_logits, faulty_logits):\n",
    "    fault_free_probs = F.softmax(fault_free_logits, dim=1)\n",
    "    faulty_probs = F.softmax(faulty_logits, dim=1)\n",
    "    ce_1 = F.cross_entropy(faulty_logits, fault_free_probs.argmax(dim=1).detach())\n",
    "    ce_2 = F.cross_entropy(fault_free_logits, faulty_probs.argmax(dim=1).detach())\n",
    "    return 0.5 * (ce_1 + ce_2)\n",
    "\n",
    "def combined_symmetric_loss(fault_free_logits, faulty_logits, alpha=0.5):\n",
    "    loss_kl = symmetric_kl_divergence(fault_free_logits, faulty_logits)\n",
    "    loss_ce = symmetric_cross_entropy(fault_free_logits, faulty_logits)\n",
    "    return alpha * loss_kl + (1 - alpha) * loss_ce  # Always positive\n",
    "\n",
    "\n",
    "# Outer loop for iterative coverage check\n",
    "while no_improve_counter_outer < OUTER_PATIENCE:\n",
    "    for i_fault in range(len(list_fault_temp)):\n",
    "        if i_fault in coverage_faults:\n",
    "            continue\n",
    "\n",
    "        # Generate a batch of random test inputs\n",
    "        test_input_pool = torch.rand((POOL_SIZE, 1, test_input_dim), requires_grad=True)\n",
    "\n",
    "        # Forward pass for the test input pool\n",
    "        with torch.no_grad():\n",
    "            output_fault_free = pnn(test_input_pool[:, 0, :])[0, 0, :, :]\n",
    "            output_faulty = pnn(test_input_pool[:, 0, :], *list_fault_temp[i_fault])[0, 0, :, :]\n",
    "            loss_per_input = F.cross_entropy(output_faulty, output_fault_free.argmax(dim=1), reduction='none')\n",
    "\n",
    "        best_input_idx = torch.argmax(loss_per_input).item()\n",
    "        test_input = test_input_pool[best_input_idx].clone().detach().requires_grad_(True)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = optim.AdamW([test_input], lr=0.01)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=20, factor=0.1)\n",
    "        best_loss = float('inf')\n",
    "        no_improvement_epochs = 0\n",
    "\n",
    "        # Inner optimization loop\n",
    "        for epoch in range(MAX_EPOCHS):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            fault_free_output = pnn(test_input)[0, 0, :, :]\n",
    "            faulty_output = pnn(test_input, *list_fault_temp[i_fault])[0, 0, :, :]\n",
    "\n",
    "            # Compute combined symmetric loss (positive-valued)\n",
    "            loss_value = combined_symmetric_loss(fault_free_output, faulty_output, alpha=0.2)\n",
    "\n",
    "            # Negate loss for maximization\n",
    "            (-loss_value).backward()  # Negative sign here to maximize\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss_value)  # Pass positive loss for scheduler\n",
    "\n",
    "            # Clamp the input\n",
    "            test_input.data.clamp_(0, 1)\n",
    "\n",
    "            # Gradient Monitoring\n",
    "            print(f\"Gradient Norm: {test_input.grad.norm().item()}\")\n",
    "\n",
    "            # Check for improvement\n",
    "            with torch.no_grad():\n",
    "                faulty_class = torch.argmax(torch.softmax(faulty_output, dim=1), dim=1).item()\n",
    "                fault_free_class = torch.argmax(torch.softmax(fault_free_output, dim=1), dim=1).item()\n",
    "\n",
    "            # Update best loss and early stopping\n",
    "            if -loss_value.item() > best_loss:  # Maximizing the loss\n",
    "                best_loss = -loss_value.item()\n",
    "                no_improvement_epochs = 0\n",
    "                if faulty_class != fault_free_class:\n",
    "                    test_input_list[i_fault] = test_input.clone().detach()\n",
    "                    coverage_faults.add(i_fault)\n",
    "            else:\n",
    "                no_improvement_epochs += 1\n",
    "\n",
    "            if no_improvement_epochs >= EARLY_STOPPING_PATIENCE:\n",
    "                print(f\"Early stopping at epoch {epoch} for fault {i_fault}\")\n",
    "                break\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {-loss_value.item()}, Fault-Free: {fault_free_class}, Faulty: {faulty_class}\")\n",
    "\n",
    "\n",
    "        print(f\"Current covered faults: {len(coverage_faults)}\")\n",
    "\n",
    "    # Evaluate test coverage progress\n",
    "    temp_test_coverage = len(coverage_faults) / len(list_fault_temp)\n",
    "    print(f\"Test Coverage: {temp_test_coverage * 100:.2f}%\")\n",
    "\n",
    "    if temp_test_coverage == test_coverage:\n",
    "        no_improve_counter_outer += 1\n",
    "    else:\n",
    "        no_improve_counter_outer = 0\n",
    "        test_coverage = temp_test_coverage\n",
    "\n",
    "# Final results\n",
    "print(f\"Final Test Coverage: {test_coverage * 100:.2f}%\")\n",
    "print(\"Covered Faults:\", coverage_faults)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Constants\n",
    "POOL_SIZE = 50\n",
    "MAX_EPOCHS = 200\n",
    "EARLY_STOPPING_PATIENCE = 20\n",
    "OUTER_PATIENCE = 5\n",
    "\n",
    "list_fault_temp = active_list_fault_sample\n",
    "coverage_faults = set()\n",
    "test_input_list = torch.zeros((len(list_fault_temp), 1, test_input_dim), requires_grad=False)\n",
    "\n",
    "test_coverage = 0\n",
    "no_improve_counter_outer = 0\n",
    "\n",
    "loss_fn_kl = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "def combined_symmetric_loss(fault_free_output, faulty_output, alpha=0.5):\n",
    "    \"\"\"Symmetric loss combining KL divergence and Cross-Entropy.\"\"\"\n",
    "    fault_free_probs = torch.softmax(fault_free_output, dim=1)\n",
    "    faulty_probs = torch.softmax(faulty_output, dim=1)\n",
    "\n",
    "    fault_free_log_probs = torch.log_softmax(fault_free_output, dim=1)\n",
    "    faulty_log_probs = torch.log_softmax(faulty_output, dim=1)\n",
    "\n",
    "    kl1 = F.kl_div(fault_free_log_probs, faulty_probs, reduction='batchmean')\n",
    "    kl2 = F.kl_div(faulty_log_probs, fault_free_probs, reduction='batchmean')\n",
    "\n",
    "    ce1 = F.cross_entropy(faulty_output, fault_free_probs.argmax(dim=1).detach())\n",
    "    ce2 = F.cross_entropy(fault_free_output, faulty_probs.argmax(dim=1).detach())\n",
    "\n",
    "    loss = alpha * (0.5 * (kl1 + kl2)) + (1 - alpha) * (0.5 * (ce1 + ce2))\n",
    "    return loss\n",
    "\n",
    "def soft_argmax(logits, beta=10):\n",
    "    \"\"\"Soft argmax implementation.\"\"\"\n",
    "    probs = F.softmax(logits * beta, dim=1)\n",
    "    indices = torch.arange(logits.size(1)).float().to(logits.device)\n",
    "    return torch.sum(probs * indices, dim=1)\n",
    "\n",
    "# Outer loop\n",
    "while no_improve_counter_outer < OUTER_PATIENCE:\n",
    "    for i_fault in range(len(list_fault_temp)):\n",
    "        if i_fault in coverage_faults:\n",
    "            continue\n",
    "\n",
    "        test_input_pool = torch.rand((POOL_SIZE, 1, test_input_dim), requires_grad=True)\n",
    "        with torch.no_grad():\n",
    "            output_fault_free = pnn(test_input_pool[:, 0, :])[0, 0, :, :]\n",
    "            output_faulty = pnn(test_input_pool[:, 0, :], *list_fault_temp[i_fault])[0, 0, :, :]\n",
    "\n",
    "            loss_per_input = F.cross_entropy(output_faulty, output_fault_free.argmax(dim=1), reduction='none')\n",
    "\n",
    "        best_input_idx = torch.argmax(loss_per_input).item()\n",
    "        test_input = test_input_pool[best_input_idx].clone().detach().requires_grad_(True)\n",
    "        optimizer = optim.AdamW([test_input], lr=0.01)\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        no_improvement_epochs = 0\n",
    "\n",
    "        # Inner loop\n",
    "        print(f\"Optimizing test input for fault {i_fault}\")\n",
    "        for epoch in range(MAX_EPOCHS):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            fault_free_output = pnn(test_input)[0, 0, :, :]\n",
    "            faulty_output = pnn(test_input, *list_fault_temp[i_fault])[0, 0, :, :]\n",
    "\n",
    "            alpha = 0.5 + 0.5 * (epoch / MAX_EPOCHS)  # Gradually increase alpha\n",
    "            loss_value = combined_symmetric_loss(fault_free_output, faulty_output, alpha=alpha)\n",
    "\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            test_input.data.clamp_(0, 1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fault_free_class = soft_argmax(fault_free_output).round().item()\n",
    "                faulty_class = soft_argmax(faulty_output).round().item()\n",
    "\n",
    "            if loss_value.item() < best_loss:\n",
    "                best_loss = loss_value.item()\n",
    "                no_improvement_epochs = 0\n",
    "                if fault_free_class != faulty_class:\n",
    "                    test_input_list[i_fault] = test_input.clone().detach()\n",
    "                    coverage_faults.add(i_fault)\n",
    "            else:\n",
    "                no_improvement_epochs += 1\n",
    "\n",
    "            if no_improvement_epochs >= EARLY_STOPPING_PATIENCE:\n",
    "                print(f\"Early stopping at epoch {epoch} for fault {i_fault}\")\n",
    "                break\n",
    "\n",
    "            if epoch % 20 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss_value.item()}, Fault-Free: {fault_free_class}, Faulty: {faulty_class}\")\n",
    "\n",
    "    temp_test_coverage = len(coverage_faults) / len(list_fault_temp)\n",
    "    print(f\"Test Coverage: {temp_test_coverage * 100:.2f}%\")\n",
    "\n",
    "    if temp_test_coverage == test_coverage:\n",
    "        no_improve_counter_outer += 1\n",
    "    else:\n",
    "        no_improve_counter_outer = 0\n",
    "        test_coverage = temp_test_coverage\n",
    "\n",
    "print(f\"Final Test Coverage: {test_coverage * 100:.2f}%\")\n",
    "print(\"Covered Faults:\", coverage_faults)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save coverage faults list and test input list to a text file\n",
    "coverage_faults_file = '../gradient_results/coverage_faults.txt'\n",
    "test_input_list_file = '../gradient_results/test_input_list.txt'\n",
    "# Save active, clustered, and all fault lists to text files\n",
    "active_faults_file = '../gradient_results/active_faults.txt'\n",
    "clustered_faults_file = '../gradient_results/clustered_faults.txt'\n",
    "all_faults_file = '../gradient_results/all_faults.txt'\n",
    "\n",
    "# Save active fault list\n",
    "with open(active_faults_file, 'w') as f:\n",
    "    for fault in active_list_fault_sample:\n",
    "        f.write(f\"{fault}\\n\")\n",
    "\n",
    "# Save clustered fault list\n",
    "with open(clustered_faults_file, 'w') as f:\n",
    "    for fault in cluster_act_list_fault_sample + cluster_inv_list_fault_sample + theta_list_fault_sample:\n",
    "        f.write(f\"{fault}\\n\")\n",
    "\n",
    "# Save all fault list\n",
    "with open(all_faults_file, 'w') as f:\n",
    "    for fault in all_act_list_fault_sample + all_inv_list_fault_sample + theta_list_fault_sample:\n",
    "        f.write(f\"{fault}\\n\")\n",
    "\n",
    "print(f\"Active faults list saved to {active_faults_file}\")\n",
    "print(f\"Clustered faults list saved to {clustered_faults_file}\")\n",
    "print(f\"All faults list saved to {all_faults_file}\")\n",
    "\n",
    "\n",
    "# Save coverage faults list\n",
    "with open(coverage_faults_file, 'w') as f:\n",
    "    for fault in coverage_faults:\n",
    "        f.write(f\"{fault}\\n\")\n",
    "\n",
    "# Save test input list\n",
    "with open(test_input_list_file, 'w') as f:\n",
    "    for test_input in test_input_list:\n",
    "        f.write(f\"{test_input.tolist()}\\n\")\n",
    "\n",
    "print(f\"Coverage faults list saved to {coverage_faults_file}\")\n",
    "print(f\"Test input list saved to {test_input_list_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = '../gradient_results/coverage_faults.txt'\n",
    "\n",
    "# Read the file and convert it to a list\n",
    "with open(file_path, 'r') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "# Convert each line to a list\n",
    "data_list = [eval(line.strip()) for line in data]\n",
    "\n",
    "# Print the data list\n",
    "print(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = '../gradient_results/test_input_list.txt'\n",
    "\n",
    "# Read the file and convert it to a list\n",
    "with open(file_path, 'r') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "# Convert each line to a list\n",
    "data_list = [eval(line.strip()) for line in data]\n",
    "\n",
    "# Print the data list\n",
    "print(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# list_fault_temp = active_list_fault_sample\n",
    "\n",
    "# coverage_faults = set()\n",
    "# test_input_list = torch.zeros((len(list_fault_temp), 1, test_input_dim), requires_grad=False)\n",
    "# # for i_fault in [5]:\n",
    "# cover_metric = 0.0\n",
    "# while cover_metric<=0.70:\n",
    "#     for i_fault in range(len(list_fault_temp)):\n",
    "        \n",
    "#         test_input_pool = torch.rand((len(list_fault_temp), 1, test_input_dim), requires_grad=False)\n",
    "\n",
    "#         # Define CrossEntropyLoss\n",
    "#         criterion = torch.nn.CrossEntropyLoss(reduction='none')  # 'none' to compute loss for each test input\n",
    "        \n",
    "#         # Define the STE module\n",
    "#         # ste_module = STEMultiClass(test_input_pool[best_test_input_index], min_value=0.0, max_value=1.0)\n",
    "\n",
    "#         # Compute fault-free and faulty outputs\n",
    "#         # ste_module.eval()\n",
    "#         # output_faulty, output_fault_free = ste_module(pnn, list_fault_temp, [i_fault])\n",
    "#         output_fault_free = pnn(test_input_pool[:, 0, :])[0, 0, :, :]  # Fault-free output\n",
    "#         output_faulty = pnn(test_input_pool[:, 0, :], *fault)[0, 0, :, :]  # Faulty output\n",
    "\n",
    "#         # Apply softmax to convert logits to probabilities\n",
    "#         output_fault_free_probs = output_fault_free.argmax(dim=1)  # Shape: (batch_size, num_classes)\n",
    "#         output_faulty_probs = F.softmax(output_faulty, dim=1)\n",
    "\n",
    "#         # Compute Cross-Entropy Loss\n",
    "#         # Comparing fault-free probabilities as the target to the faulty probabilities\n",
    "#         loss_per_test_input = criterion(output_faulty_probs, output_fault_free_probs)  # Shape: (batch_size,)\n",
    "\n",
    "#         # Identify the best test input (highest loss)\n",
    "#         best_test_input_index = torch.argmax(loss_per_test_input).item()\n",
    "        \n",
    "#         loss_tracks = []\n",
    "#         # class_tracks = []\n",
    "\n",
    "#         # Define the optimizer for input optimization\n",
    "#         test_input_list[i_fault] = test_input_pool[best_test_input_index].clone().detach()\n",
    "#         test_input = test_input_pool[best_test_input_index].clone().detach().requires_grad_(True)\n",
    "#         optimizer = optim.Adam([test_input], lr=0.01)\n",
    "#         num_epochs = 200\n",
    "#         early_stopping_patience = 10\n",
    "#         # loss = torch.nn.L1Loss()\n",
    "#         # loss = torch.nn.CrossEntropyLoss()\n",
    "#         # Use KL Divergence as the loss\n",
    "#         loss_fn = torch.nn.KLDivLoss(reduction='batchmean')  # KL divergence expects log probabilities\n",
    "        \n",
    "#         best_loss = float('inf')\n",
    "#         no_improvement_epochs = 0  # Counter for early stopping\n",
    "        \n",
    "\n",
    "#         # Training loop\n",
    "#         for epoch in range(num_epochs):\n",
    "#             # ste_module.train()\n",
    "#             # Zero gradients\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # Forward pass\n",
    "#             # faulty_output, fault_free_output = ste_module(pnn, list_fault_temp, [i_fault])\n",
    "            \n",
    "#             # Forward pass through the fault-free and faulty models\n",
    "#             fault_free_output = pnn(test_input)[0, 0, :, :]  # Fault-free model\n",
    "#             faulty_output = pnn(test_input, *list_fault_temp[i_fault])[0, 0, :, :]  # Faulty model\n",
    "\n",
    "            \n",
    "#             # Apply softmax and log for KL divergence\n",
    "#             faulty_probs = torch.log_softmax(faulty_output, dim=1)  # Log probabilities\n",
    "#             fault_free_probs = torch.softmax(fault_free_output, dim=1)  # Probabilities\n",
    "\n",
    "#             # Compute loss\n",
    "#             # Compute KL divergence loss\n",
    "#             loss_value = -loss_fn(faulty_probs, fault_free_probs)  # Negate to maximize difference\n",
    "\n",
    "#             loss_tracks.append(loss_value.detach().item())\n",
    "            \n",
    "#             faulty_class = torch.argmax(torch.softmax(faulty_output, dim=1).detach(), dim=1).item()\n",
    "#             fault_free_class = torch.argmax(torch.softmax(fault_free_output, dim=1).detach(), dim=1).item()\n",
    "            \n",
    "#             if (best_loss > loss_value.detach().item()) and (faulty_class != fault_free_class):\n",
    "#                     best_loss = loss_value.detach().item()\n",
    "#                     test_input_list[i_fault] = test_input.clone().detach()\n",
    "#                     coverage_faults.add(int(i_fault))\n",
    "\n",
    "#             if loss_value.item() >= best_loss - 1e-6:  # Improvement threshold\n",
    "#                 no_improvement_epochs += 1\n",
    "                \n",
    "#             # Early stopping check\n",
    "#             if no_improvement_epochs >= early_stopping_patience:\n",
    "#                 print(f\"Early stopping at epoch {epoch} for fault {i_fault}\")\n",
    "#                 break\n",
    "            \n",
    "#             # Print progress\n",
    "#             if (epoch) % 50 == 0:\n",
    "#                 print(f\"Fault: {i_fault}, Epoch: {epoch}\")\n",
    "#                 print(\"Fault-Free Output:\", fault_free_class) # Convert to numpy for readability\n",
    "#                 print(\"Faulty Output:\", faulty_class)\n",
    "                    \n",
    "#             # Backward pass and optimization\n",
    "#             loss_value.backward()\n",
    "            \n",
    "#             optimizer.step()\n",
    "            \n",
    "#             # Clamp test input to valid range [0, 1] AFTER optimizer updates it\n",
    "#             test_input.data.clamp_(0, 1)\n",
    "            \n",
    "#     cover_metric = len(coverage_faults) / len(list_fault_temp)\n",
    "    \n",
    "#     # plt.plot(loss_tracks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all values are positive\n",
    "all(v >= 0 for v in test_input_list.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coverage_faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coverage_faults) / len(list_fault_temp) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate indices for each fault type\n",
    "num_act_faults = len(active_cluster_act_list_fault_sample)\n",
    "num_inv_faults = len(active_cluster_inv_list_fault_sample)\n",
    "num_theta_faults = len(active_cluster_theta_list_fault_sample)\n",
    "\n",
    "# Calculate start and end indices for each fault type in active_list_fault_sample\n",
    "act_fault_indices = set(range(num_act_faults))\n",
    "inv_fault_indices = set(range(num_act_faults, num_act_faults + num_inv_faults))\n",
    "theta_fault_indices = set(range(num_act_faults + num_inv_faults, len(active_list_fault_sample)))\n",
    "\n",
    "# Compute coverage for each fault type\n",
    "covered_act_faults = act_fault_indices & coverage_faults\n",
    "covered_inv_faults = inv_fault_indices & coverage_faults\n",
    "covered_theta_faults = theta_fault_indices & coverage_faults\n",
    "\n",
    "# Calculate coverage metrics\n",
    "act_coverage = len(covered_act_faults) / num_act_faults if num_act_faults > 0 else 0\n",
    "inv_coverage = len(covered_inv_faults) / num_inv_faults if num_inv_faults > 0 else 0\n",
    "theta_coverage = len(covered_theta_faults) / num_theta_faults if num_theta_faults > 0 else 0\n",
    "\n",
    "# Print results\n",
    "print(\"Test Coverage Metrics:\")\n",
    "print(f\"Total ACT Faults: {num_act_faults}, Covered: {len(covered_act_faults)}, Coverage: {act_coverage:.2%}\")\n",
    "print(f\"Total INV Faults: {num_inv_faults}, Covered: {len(covered_inv_faults)}, Coverage: {inv_coverage:.2%}\")\n",
    "print(f\"Total THETA Faults: {num_theta_faults}, Covered: {len(covered_theta_faults)}, Coverage: {theta_coverage:.2%}\")\n",
    "\n",
    "\n",
    "covered_act_faults = len(covered_act_faults)\n",
    "covered_inv_faults = len(covered_inv_faults)\n",
    "covered_theta_faults = len(covered_theta_faults)\n",
    "\n",
    "# Calculate uncovered faults for each type\n",
    "uncovered_act_faults = num_act_faults - covered_act_faults\n",
    "uncovered_inv_faults = num_inv_faults - covered_inv_faults\n",
    "uncovered_theta_faults = num_theta_faults - covered_theta_faults\n",
    "\n",
    "# Data for the pie chart\n",
    "sizes = [\n",
    "    covered_act_faults, uncovered_act_faults,\n",
    "    covered_inv_faults, uncovered_inv_faults,\n",
    "    covered_theta_faults, uncovered_theta_faults\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    \"p-tanh   Covered\", \"p-tanh Uncovered\",\n",
    "    \"Inverter Covered\", \"Inverter Uncovered\",\n",
    "    \"crossbar Covered\", \"crossbar Uncovered\"\n",
    "]\n",
    "\n",
    "# Define main colors and hover colors\n",
    "colors = [\n",
    "    '#1f77b4', '#aec7e8',  # ACT main and hover (blue shades)\n",
    "    '#ff7f0e', '#ffbb78',  # INV main and hover (orange shades)\n",
    "    '#2ca02c', '#98df8a'   # THETA main and hover (green shades)\n",
    "]\n",
    "\n",
    "\n",
    "# Create the pie chart\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    sizes, labels=None, autopct='%1.1f%%', startangle=140, colors=colors,\n",
    "    pctdistance=0.85, wedgeprops=dict(width=0.3)  # Adjust width to create a donut\n",
    ")\n",
    "\n",
    "# Add legend inside the ring\n",
    "ax.legend(wedges, labels, loc=\"center\", fontsize=16, title_fontsize=18, frameon=False,)\n",
    "\n",
    "# Add title and customize font\n",
    "ax.set_title(\"Test Coverage Distribution Across Fault Types\", fontsize=16, fontweight='bold')\n",
    "\n",
    "# Enhance label visibility\n",
    "for text in texts:\n",
    "    text.set_fontsize(16)\n",
    "for autotext in autotexts:\n",
    "    autotext.set_fontsize(16)\n",
    "    autotext.set_fontweight('bold')\n",
    "\n",
    "# Layout adjustments\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute on Optimized Test Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "results = []  # List to store evaluation results\n",
    "covered_faults = set()  # Track covered faults during evaluation\n",
    "type_fault = \"ALL\"  # Replace with the actual fault type\n",
    "\n",
    "# Loop over all saved test inputs\n",
    "for i_fault, best_test_input in enumerate(test_input_list):\n",
    "    if i_fault not in coverage_faults:  # Skip faults not covered during training\n",
    "        continue\n",
    "\n",
    "    print(f\"Re-evaluating Fault: {i_fault}\")\n",
    "    best_test_input = best_test_input.unsqueeze(0)  # Ensure the input has the correct batch dimension\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        # Forward pass for fault-free and faulty models\n",
    "        fault_free_output = pnn(best_test_input)[0, 0, :, :]\n",
    "        faulty_output = pnn(best_test_input, *list_fault_temp[i_fault])[0, 0, :, :]\n",
    "\n",
    "        # Compute probabilities\n",
    "        fault_free_probs = F.softmax(fault_free_output, dim=1)\n",
    "        faulty_probs = F.softmax(faulty_output, dim=1)\n",
    "\n",
    "        # Compute classification results\n",
    "        fault_free_class = torch.argmax(fault_free_probs, dim=1).item()\n",
    "        faulty_class = torch.argmax(faulty_probs, dim=1).item()\n",
    "\n",
    "        # Check if the test input distinguishes the fault-free and faulty models\n",
    "        if fault_free_class != faulty_class:\n",
    "            covered_faults.add(i_fault)  # Add to covered faults set\n",
    "\n",
    "        # Save result for this fault\n",
    "        results.append({\n",
    "            \"fault_index\": i_fault,\n",
    "            \"test_input\": best_test_input.squeeze(0).tolist(),  # Convert tensor to list\n",
    "            \"fault_free_class\": fault_free_class,\n",
    "            \"faulty_class\": faulty_class,\n",
    "            \"is_covered\": fault_free_class != faulty_class,  # True if covered, False otherwise\n",
    "            \"num_epochs\": num_epochs,\n",
    "        })\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Fault-Free Class: {fault_free_class}, Faulty Class: {faulty_class}\")\n",
    "\n",
    "# Save results and covered faults to files\n",
    "dataset_name = args.DATASET  # Replace with the actual dataset name\n",
    "results_file = f\"../gradient_results/{type_fault}_{dataset_name}_evaluation_results.json\"\n",
    "covered_faults_file = f\"../gradient_results/{type_fault}_{dataset_name}_covered_faults.json\"\n",
    "\n",
    "# Save detailed results\n",
    "with open(results_file, \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "# Save covered faults separately\n",
    "with open(covered_faults_file, \"w\") as f:\n",
    "    json.dump(list(covered_faults), f, indent=4)\n",
    "\n",
    "print(f\"Results saved to {results_file}\")\n",
    "print(f\"Covered faults saved to {covered_faults_file}\")\n",
    "print(f\"Total Covered Faults: {len(covered_faults)}/{len(list_fault_temp)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# File paths\n",
    "dataset_name = args.DATASET  # Replace with your dataset name, e.g., \"CIFAR10\"\n",
    "results_file = f\"../gradient_results/{type_fault}_{dataset_name}_evaluation_results.json\"\n",
    "covered_faults_file = f\"../gradient_results/{type_fault}_{dataset_name}_covered_faults.json\"\n",
    "\n",
    "# Load evaluation results\n",
    "with open(results_file, \"r\") as f:\n",
    "    evaluation_results = json.load(f)\n",
    "\n",
    "# Display some results\n",
    "print(f\"Loaded {len(evaluation_results)} evaluation results.\")\n",
    "for result in evaluation_results[:5]:  # Display the first 5 results\n",
    "    print(f\"Fault Index: {result['fault_index']}\")\n",
    "    print(f\"Test Input: {result['test_input'][:10]}...\")  # Show only the first 10 values\n",
    "    print(f\"Fault-Free Class: {result['fault_free_class']}\")\n",
    "    print(f\"Faulty Class: {result['faulty_class']}\")\n",
    "    print(f\"Is Covered: {result['is_covered']}\")\n",
    "    print(f\"Num Epochs: {result['num_epochs']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetate Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data from the uploaded chart\n",
    "labels = [\n",
    "    \"p-tanh Covered\",\n",
    "    \"p-tanh Uncovered\",\n",
    "    \"Inverter Covered\",\n",
    "    \"Inverter Uncovered\",\n",
    "    \"Crossbar Covered\",\n",
    "    \"Crossbar Uncovered\",\n",
    "]\n",
    "sizes = [28.5, 0.0, 39.0, 4.9, 26.0, 1.6]  # Percentages\n",
    "\n",
    "# Update colors: Replace orange with red and adjust the green shade\n",
    "updated_main_colors = [\"#1f77b4\", \"#d62728\", \"#228B22\"]  # Blue, Red, Modified Green\n",
    "updated_lighter_colors = [\"#aec7e8\", \"#ff9896\", \"#90EE90\"]  # Lighter Blue, Lighter Red, Lighter Green\n",
    "\n",
    "# Combine updated colors\n",
    "final_colors = [\n",
    "    updated_main_colors[0], updated_lighter_colors[0],  # p-tanh\n",
    "    updated_main_colors[1], updated_lighter_colors[1],  # Inverter\n",
    "    updated_main_colors[2], updated_lighter_colors[2],  # Crossbar\n",
    "]\n",
    "\n",
    "# Create a pie chart with bolder and bigger fonts for clarity\n",
    "plt.figure(figsize=(8, 8))\n",
    "wedges, texts, autotexts = plt.pie(\n",
    "    sizes,\n",
    "    labels=None,  # Remove labels from the pie itself\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=90,\n",
    "    colors=final_colors,\n",
    "    textprops={\"fontsize\": 18, \"fontweight\": \"bold\"},  # Bigger, bolder text for percentages\n",
    ")\n",
    "\n",
    "# Add a title to the chart\n",
    "plt.title(\"AcuteInflam\", fontsize=22, fontweight=\"bold\", y=0.92) \n",
    "\n",
    "# # Customize legend for better clarity\n",
    "# plt.legend(\n",
    "#     wedges, \n",
    "#     labels, \n",
    "#     title=\"Fault Types\", \n",
    "#     loc=\"center left\", \n",
    "#     bbox_to_anchor=(1, 0.5), \n",
    "#     fontsize=12, \n",
    "#     title_fontsize=14, \n",
    "#     frameon=True,\n",
    "# )\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))  # 2 rows x 4 columns grid layout for 8 pie charts\n",
    "# fig.suptitle(\"Multiple Pie Charts\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "# Titles for the 8 charts (can be customized)\n",
    "titles = [f\"Chart {i+1}\" for i in range(8)]\n",
    "\n",
    "labels = [\n",
    "    \"p-tanh (Covered)\",\n",
    "    \"p-tanh (Uncovered)\",\n",
    "    \"Inverter (Covered)\",\n",
    "    \"Inverter (Uncovered)\",\n",
    "    \"Crossbar (Covered)\",\n",
    "    \"Crossbar (Uncovered)\",\n",
    "]\n",
    "\n",
    "# Data for the 8 pie charts\n",
    "percentages = {'AcuteInflam': [28.5, 0.0, 39.0, 4.9, 26.0, 1.6],\n",
    "            #    '': [20.8, 2.8, 38.2, 2.2, 33.1, 2.8],\n",
    "               'BreastCancWisc': [22.7, 0.0, 27.3, 0.8, 49.2, 0.0],\n",
    "               'Cardiotoco3': [19.6, 0.0, 48.6, 1.9, 29.4, 0.5],\n",
    "               'Iris': [27.3, 0.0, 32.5, 2.6, 37.7, 0.0],\n",
    "               'Pendigits': [19.6, 0.7, 34.2, 0.0, 44.4, 1.1],\n",
    "               'Seeds': [20.9, 0.0, 37.3, 3.0, 38.3, 0.5],\n",
    "               'TicTacToe': [20.3, 2.6, 23.5, 0.0, 42.5, 11.1],\n",
    "            #    'VertCol2': [19.4, 0.0, 27.2, 17.8, 22.8, 12.8],\n",
    "               'VertCol3': [28.2, 0.0, 35.5, 0.8, 35.5, 0.0],}\n",
    "\n",
    "# Iterate through each axis and create a pie chart\n",
    "for ax, title in zip(axes.flat, percentages.keys()):\n",
    "    wedges, texts, autotexts = ax.pie(\n",
    "        percentages[title],\n",
    "        labels=None,  # No labels directly on the pie\n",
    "        autopct=\"%1.0f%%\",\n",
    "        startangle=90,\n",
    "        colors=final_colors,\n",
    "        textprops={\"fontsize\": 12, \"fontweight\": \"bold\"},  # Adjust text size for space\n",
    "    )\n",
    "    ax.set_title(title, fontsize=14, pad=5, fontweight=\"bold\", y=0.92)  # Add title above each pie chart\n",
    "\n",
    "# Add a single shared legend\n",
    "fig.legend(\n",
    "    wedges,\n",
    "    labels,\n",
    "    title=\"Fault Locations\",\n",
    "    loc=\"center right\",\n",
    "    fontsize=15,\n",
    "    title_fontsize=15,\n",
    "    frameon=True,\n",
    "    # prop={\"weight\": \"bold\"},\n",
    "    # borderpad=-1,  # Add padding inside the frame\n",
    "    labelspacing=1.1,  # Increase spacing between legend entries\n",
    "    bbox_to_anchor=(1.081, 0.5)\n",
    ")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 0.95])  # Adjust layout to fit everything\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(percentages.keys())[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lighter colors for the segments\n",
    "lighter_final_colors = [\n",
    "    \"#A6C8E0\", \"#D6EAF5\",  # Lighter Blue shades for p-tanh\n",
    "    \"#F5A3A3\", \"#FBCBCB\",  # Lighter Red shades for Inverter\n",
    "    \"#A9E5A3\", \"#D3F2CF\",  # Lighter Green shades for Crossbar\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))  # Increase figure size for readability\n",
    "\n",
    "# Create a grid layout for 2 rows x 4 columns for the first 8 charts\n",
    "axes = [plt.subplot2grid((2, 5), (i // 4, i % 4)) for i in range(8)]\n",
    "\n",
    "# Titles for the 9 charts (can be customized)\n",
    "titles = [f\"Chart {i+1}\" for i in range(9)]\n",
    "\n",
    "labels = [\n",
    "    \"p-tanh (Covered)\",\n",
    "    \"p-tanh (Uncovered)\",\n",
    "    \"Inverter (Covered)\",\n",
    "    \"Inverter (Uncovered)\",\n",
    "    \"Crossbar (Covered)\",\n",
    "    \"Crossbar (Uncovered)\",\n",
    "]\n",
    "\n",
    "# Data for the 8 pie charts\n",
    "percentages = {'AcuteInflam': [28.5, 0.0, 39.0, 4.9, 26.0, 1.6],\n",
    "            #    '': [20.8, 2.8, 38.2, 2.2, 33.1, 2.8],\n",
    "               'BreastCancWisc': [22.7, 0.0, 27.3, 0.8, 49.2, 0.0],\n",
    "               'Cardiotoco3': [19.6, 0.0, 48.6, 1.9, 29.4, 0.5],\n",
    "               'Iris': [27.3, 0.0, 32.5, 2.6, 37.7, 0.0],\n",
    "               'Pendigits': [19.6, 0.7, 34.2, 0.0, 44.4, 1.1],\n",
    "               'Seeds': [20.9, 0.0, 37.3, 3.0, 38.3, 0.5],\n",
    "               'TicTacToe': [20.3, 2.6, 23.5, 0.0, 42.5, 11.1],\n",
    "               'VertCol2': [19.4, 0.0, 27.2, 17.8, 22.8, 12.8],\n",
    "               'VertCol3': [28.2, 0.0, 35.5, 0.8, 35.5, 0.0],}\n",
    "\n",
    "# Plot the first 8 pie charts\n",
    "for title, ax in zip(list(percentages.keys())[0:8], axes):\n",
    "    wedges, texts, autotexts = ax.pie(\n",
    "        percentages[title],\n",
    "        labels=None,  # No labels directly on the pie\n",
    "        autopct=\"%1.0f%%\",\n",
    "        startangle=90,\n",
    "        colors=lighter_final_colors,\n",
    "        textprops={\"fontsize\": 14, \"fontweight\": \"bold\"},  # Adjust text size for space\n",
    "    )\n",
    "    ax.set_title(title, fontsize=15, pad=5, fontweight=\"bold\", y=0.9)  # Add title above each pie chart\n",
    "\n",
    "# Add the legend in the top-right corner, closer to the plots\n",
    "legend_ax = fig.add_axes([0.78, 0.65, 0.2, 0.3])  # Adjust position and size of the legend box\n",
    "legend_ax.axis(\"off\")  # Turn off the axis for the legend box\n",
    "legend_ax.legend(\n",
    "    wedges,\n",
    "    labels,\n",
    "    title=\"Fault Locations\",\n",
    "    loc=\"center\",\n",
    "    fontsize=13,  # Larger font for labels\n",
    "    title_fontsize=13,  # Larger font for the legend title\n",
    "    frameon=True,  # Add a frame around the legend\n",
    "    # borderpad=1.2,  # Padding inside the frame\n",
    "    # labelspacing=1.1,  # Spacing between legend items\n",
    "    bbox_to_anchor=(0.55, 0.4)\n",
    ")\n",
    "\n",
    "# Add the ninth pie chart beside the eighth chart\n",
    "ax9 = plt.subplot2grid((2, 5), (1, 4))  # Place beside the 8th chart\n",
    "ax9.pie(\n",
    "    [28.2, 0.0, 35.5, 0.8, 35.5, 0.0],\n",
    "    labels=None,  # No labels directly on the pie\n",
    "    autopct=\"%1.0f%%\",\n",
    "    startangle=90,\n",
    "    colors=lighter_final_colors,\n",
    "    textprops={\"fontsize\": 14, \"fontweight\": \"bold\"},  # Adjust text size for space\n",
    ")\n",
    "ax9.set_title(list(percentages.keys())[-1], fontsize=15, pad=5, fontweight=\"bold\", y=0.90)  # Add title above each pie chart\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.19)  # Fine-tune spacing between plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define lighter colors for the segments\n",
    "lighter_final_colors = [\n",
    "    \"#A6C8E0\", \"#D6EAF5\",  # Lighter Blue shades for p-tanh\n",
    "    \"#F5A3A3\", \"#FBCBCB\",  # Lighter Red shades for Inverter\n",
    "    \"#A9E5A3\", \"#D3F2CF\",  # Lighter Green shades for Crossbar\n",
    "]\n",
    "\n",
    "# Data for the pie charts\n",
    "percentages = {\n",
    "    'AcuteInflam': [28.5, 0.0, 39.0, 4.9, 26.0, 1.6],\n",
    "    'BreastCancWisc': [22.7, 0.0, 27.3, 0.8, 49.2, 0.0],\n",
    "    'Cardiotoco3': [19.6, 0.0, 48.6, 1.9, 29.4, 0.5],\n",
    "    'Iris': [27.3, 0.0, 32.5, 2.6, 37.7, 0.0],\n",
    "    'Pendigits': [19.6, 0.7, 34.2, 0.0, 44.4, 1.1],\n",
    "    'Seeds': [20.9, 0.0, 37.3, 3.0, 38.3, 0.5],\n",
    "    'TicTacToe': [20.3, 2.6, 23.5, 0.0, 42.5, 11.1],\n",
    "    'VertCol2': [19.4, 0.0, 27.2, 17.8, 22.8, 12.8],\n",
    "    'VertCol3': [28.2, 0.0, 35.5, 0.8, 35.5, 0.0],\n",
    "}\n",
    "\n",
    "labels = [\n",
    "    \"p-tanh (Covered)\",\n",
    "    \"p-tanh (Uncovered)\",\n",
    "    \"Inverter (Covered)\",\n",
    "    \"Inverter (Uncovered)\",\n",
    "    \"Crossbar (Covered)\",\n",
    "    \"Crossbar (Uncovered)\",\n",
    "]\n",
    "\n",
    "# Set up figure\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))  # 2 rows x 5 columns\n",
    "axes = axes.flatten()  # Flatten axes for easy indexing\n",
    "\n",
    "# Plot the pie charts\n",
    "for i, (title, data) in enumerate(percentages.items()):\n",
    "    wedges, _, autotexts = axes[i].pie(\n",
    "        data, \n",
    "        labels=None,  # No direct labels\n",
    "        autopct='%1.0f%%',\n",
    "        startangle=90,\n",
    "        colors=lighter_final_colors,\n",
    "        textprops={\"fontsize\": 10, \"fontweight\": \"bold\"},\n",
    "    )\n",
    "    axes[i].set_title(title, fontsize=12, pad=5, fontweight=\"bold\")\n",
    "\n",
    "# Remove any unused axes\n",
    "for j in range(len(percentages), len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Add a shared legend below the subplots\n",
    "fig.legend(\n",
    "    wedges, labels, loc='lower center', bbox_to_anchor=(0.5, -0.05),\n",
    "    ncol=3, fontsize=11, title=\"Fault Locations\", title_fontsize=12\n",
    ")\n",
    "\n",
    "plt.tight_layout(pad=1.5)\n",
    "plt.subplots_adjust(bottom=0.15)  # Adjust bottom space for legend\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = {'AcuteInflam': [28.5, 0.0, 39.0, 4.9, 26.0, 1.6],\n",
    "            #    '': [20.8, 2.8, 38.2, 2.2, 33.1, 2.8],\n",
    "               'BreastCancWisc': [22.7, 0.0, 27.3, 0.8, 49.2, 0.0],\n",
    "               'Cardiotoco3': [19.6, 0.0, 48.6, 1.9, 29.4, 0.5],\n",
    "               'Iris': [27.3, 0.0, 32.5, 2.6, 37.7, 0.0],\n",
    "               'Pendigits': [19.6, 0.7, 34.2, 0.0, 44.4, 1.1],\n",
    "               'Seeds': [20.9, 0.0, 37.3, 3.0, 38.3, 0.5],\n",
    "               'TicTacToe': [20.3, 2.6, 23.5, 0.0, 42.5, 11.1],\n",
    "               'VertCol2': [19.4, 0.0, 27.2, 17.8, 22.8, 12.8],\n",
    "               'VertCol3': [28.2, 0.0, 35.5, 0.8, 35.5, 0.0],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Adjust layout to bring the second row closer to the upper row\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m7\u001b[39m))  \u001b[38;5;66;03m# Reduce overall height to bring rows closer\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create a grid layout for 2 rows x 4 columns for the first 8 charts\u001b[39;00m\n\u001b[1;32m      5\u001b[0m axes \u001b[38;5;241m=\u001b[39m [plt\u001b[38;5;241m.\u001b[39msubplot2grid((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m), (i \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m, i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m4\u001b[39m), rowspan\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Adjust layout to bring the second row closer to the upper row\n",
    "fig = plt.figure(figsize=(14, 7))  # Reduce overall height to bring rows closer\n",
    "\n",
    "# Create a grid layout for 2 rows x 4 columns for the first 8 charts\n",
    "axes = [plt.subplot2grid((2, 5), (i // 4, i % 4), rowspan=1) for i in range(8)]\n",
    "\n",
    "# Titles for the 9 charts (can be customized)\n",
    "titles = [f\"Chart {i+1}\" for i in range(9)]\n",
    "\n",
    "# Plot the first 8 pie charts\n",
    "for i, ax in enumerate(axes):\n",
    "    wedges, texts, autotexts = ax.pie(\n",
    "        sizes,\n",
    "        labels=None,  # No labels directly on the pie\n",
    "        autopct=\"%1.0f%%\",\n",
    "        startangle=90,\n",
    "        colors=lighter_final_colors,\n",
    "        textprops={\"fontsize\": 10, \"fontweight\": \"bold\"},  # Adjust font for space\n",
    "    )\n",
    "    ax.set_title(titles[i], fontsize=12, pad=5)  # Add titles with smaller padding\n",
    "\n",
    "# Add the legend in the top-right corner, closer to the plots\n",
    "legend_ax = fig.add_axes([0.78, 0.65, 0.2, 0.3])  # Adjust position and size of the legend box\n",
    "legend_ax.axis(\"off\")  # Turn off the axis for the legend box\n",
    "legend_ax.legend(\n",
    "    wedges,\n",
    "    labels,\n",
    "    title=\"Covered and Uncovered Faults\",\n",
    "    loc=\"center\",\n",
    "    fontsize=12,  # Larger font for labels\n",
    "    title_fontsize=14,  # Larger font for the legend title\n",
    "    frameon=True,  # Add a frame around the legend\n",
    "    borderpad=1.2,  # Padding inside the frame\n",
    "    labelspacing=1.0,  # Spacing between legend items\n",
    ")\n",
    "\n",
    "# Add the ninth pie chart beside the eighth chart\n",
    "ax9 = plt.subplot2grid((2, 5), (1, 4), rowspan=1)  # Place beside the 8th chart\n",
    "ax9.pie(\n",
    "    sizes,\n",
    "    labels=None,  # No labels directly on the pie\n",
    "    autopct=\"%1.0f%%\",\n",
    "    startangle=90,\n",
    "    colors=lighter_final_colors,\n",
    "    textprops={\"fontsize\": 10, \"fontweight\": \"bold\"},  # Adjust font for space\n",
    ")\n",
    "ax9.set_title(titles[8], fontsize=12, pad=5)  # Add title for the ninth chart\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Create a box plot for the red data\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "boxprops = dict(linewidth=2, color='k')  # Border props\n",
    "medianprops = dict(linewidth=2, color='black')\n",
    "meanprops = dict(marker='o', markerfacecolor='black', markersize=8)\n",
    "\n",
    "red_data = np.random.normal(0.3, 0.7, 100)\n",
    "box = ax.boxplot(red_data, patch_artist=True, boxprops=boxprops, medianprops=medianprops, meanprops=meanprops, showmeans=False)\n",
    "\n",
    "# Set the color of the box plot\n",
    "for patch in box['boxes']:\n",
    "    patch.set_facecolor('red')\n",
    "\n",
    "# Set the title and labels\n",
    "ax.set_title('Red Box Plot')\n",
    "ax.set_ylabel('Values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "# Create a box plot for the blue data\n",
    "fig, ax = plt.subplots()\n",
    "blue_data = np.random.normal(0.5, 0.3, 100)\n",
    "box = ax.boxplot(blue_data, patch_artist=True, boxprops=boxprops, medianprops=medianprops, meanprops=meanprops, showmeans=False)\n",
    "\n",
    "# Set the color of the box plot\n",
    "for patch in box['boxes']:\n",
    "    patch.set_facecolor('blue')\n",
    "\n",
    "# Set the title and labels\n",
    "ax.set_title('Blue Box Plot')\n",
    "ax.set_ylabel('Values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate synthetic faulty dataset\n",
    "np.random.seed(0)\n",
    "red_data = np.random.normal(1.2, 0.1, 50)  # Faulty data (red)\n",
    "\n",
    "# Combine data into a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    \"Red Fault\": red_data\n",
    "})\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "boxprops = dict(linewidth=2, color='k')  # Border props\n",
    "medianprops = dict(linewidth=2, color='black')\n",
    "meanprops = dict(marker='o', markerfacecolor='black', markersize=8)\n",
    "\n",
    "# Boxplot with red color\n",
    "box = data[['Red Fault']].plot(\n",
    "    kind='box',\n",
    "    color=dict(boxes=['red']),\n",
    "    patch_artist=True,  # Fill boxes\n",
    "    showmeans=True,\n",
    "    medianprops=medianprops,\n",
    "    boxprops=boxprops,\n",
    "    meanprops=meanprops,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Customize plot\n",
    "plt.title(\"Red Box Plot\")\n",
    "plt.xticks([1], ['Red'])\n",
    "plt.ylabel(\"Values\")\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
